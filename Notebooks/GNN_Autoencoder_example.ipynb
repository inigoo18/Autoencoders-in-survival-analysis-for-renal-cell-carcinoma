{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "176c13f7-2cd0-4338-add4-778da779634f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import mygene\n",
    "import torch\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e7cc858-246f-462b-8f93-661b2b46f0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, Sequential\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "from torch_geometric.nn import GAE\n",
    "from torch_geometric.data import Data, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4c3cfe5-9ca0-46ae-b099-20dd402921f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Type\n",
    "\n",
    "import torch\n",
    "import torch_geometric\n",
    "\n",
    "from torch.nn import Linear, ReLU,Dropout\n",
    "from torch_geometric.nn import Sequential, GCNConv, TopKPooling\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class GNNExample(nn.Module):\n",
    "    def __init__(self, num_features, input_dim, num_samples, L, batch_size):\n",
    "        super(GNNExample, self).__init__()\n",
    "        self.conv = GCNConv(num_features, num_features)\n",
    "        self.batch_size = batch_size\n",
    "        self.input_dim = input_dim\n",
    "        self.num_features = num_features\n",
    "        self.num_samples = num_samples\n",
    "\n",
    "    def convolute(self, data):\n",
    "        xs = torch.tensor([])\n",
    "        for i in range(len(data)):\n",
    "            x, edge_index = data[i].x, data[i].edge_index\n",
    "            h = self.conv(x, edge_index)\n",
    "            h = h.sigmoid()\n",
    "            xs = torch.cat([xs, h])\n",
    "        return xs\n",
    "\n",
    "    def forward(self, data):\n",
    "        xs = self.convolute(data)\n",
    "        xs = torch.reshape(xs, (self.num_samples, self.input_dim))\n",
    "        return xs\n",
    "\n",
    "    def get_latent_space(self, data):\n",
    "        xs = self.convolute(data)\n",
    "        xs = torch.reshape(xs, (self.batch_size, self.input_dim))\n",
    "        return xs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c14c8a08-2d31-41e4-8d8c-8c301abd09d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Type\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "class MWE_AE(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, L):\n",
    "        super().__init__()\n",
    "\n",
    "        print(\"Initializing Minimal Working Example AE with input dim: \", input_dim)\n",
    "\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            custom_block(input_dim, 2500),\n",
    "            custom_block(2500, 2000),\n",
    "            custom_block(2000, 1500),\n",
    "            custom_block(1500, 1200),\n",
    "            custom_block(1200, 1000),\n",
    "            custom_block(1000, 800),\n",
    "            custom_block(800, 600),\n",
    "            custom_block(600, 400),\n",
    "            custom_block(400, 300),\n",
    "            custom_block(300, 150),\n",
    "            custom_block(150, 100),\n",
    "            custom_block(100, 50),\n",
    "            custom_block(50, L),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            custom_block(L, 50),\n",
    "            custom_block(50, 100),\n",
    "            custom_block(100, 150),\n",
    "            custom_block(150, 300),\n",
    "            custom_block(300, 400),\n",
    "            custom_block(400, 600),\n",
    "            custom_block(600, 800),\n",
    "            custom_block(800, 1000),\n",
    "            custom_block(1000, 1200),\n",
    "            custom_block(1200, 1500),\n",
    "            custom_block(1500, 2000),\n",
    "            custom_block(2000, 2500),\n",
    "            custom_block(2500, input_dim),\n",
    "            torch.nn.BatchNorm1d(input_dim),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "    def get_latent_space(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "\n",
    "def custom_block(input_dim, output_dim, dropout_rate=0.4):\n",
    "    return torch.nn.Sequential(\n",
    "        torch.nn.Linear(input_dim, output_dim),\n",
    "        torch.nn.BatchNorm1d(output_dim),\n",
    "        torch.nn.PReLU(),\n",
    "        torch.nn.Dropout(dropout_rate)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9e0c6b49-afa7-4286-8090-8f2ea447602c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset():\n",
    "    \"\"\"\n",
    "    This class is used to have all types of data in one place. For example, the entire train set can be housed\n",
    "    within this class. This way when we need to merge genData and cliData together, it can be done easily, as well\n",
    "    as checking the labels for later use.\n",
    "    \"\"\"\n",
    "    def __init__(self, genData, cliData, labels):\n",
    "        self.genData = genData\n",
    "        self.cliData = cliData\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.genData)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.genData[idx], self.cliData[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddeaa6d-76af-45d6-902d-af8260190b01",
   "metadata": {},
   "source": [
    "### TABULAR SIDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "d857fa1c-7066-4c4c-87d2-1882c1f3218f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NFKB1</th>\n",
       "      <th>TNIP2</th>\n",
       "      <th>AMOT</th>\n",
       "      <th>VASP</th>\n",
       "      <th>SS18L1</th>\n",
       "      <th>SMARCA4</th>\n",
       "      <th>SMURF1</th>\n",
       "      <th>HSPA5</th>\n",
       "      <th>SKIL</th>\n",
       "      <th>UBE2I</th>\n",
       "      <th>...</th>\n",
       "      <th>SULF2</th>\n",
       "      <th>CD276</th>\n",
       "      <th>TIPARP</th>\n",
       "      <th>PFS_P</th>\n",
       "      <th>PFS_P_CNSR</th>\n",
       "      <th>MATH</th>\n",
       "      <th>HE_TUMOR_CELL_CONTENT_IN_TUMOR_AREA</th>\n",
       "      <th>PD-L1_TOTAL_IMMUNE_CELLS_PER_TUMOR_AREA</th>\n",
       "      <th>CD8_POSITIVE_CELLS_TUMOR_CENTER</th>\n",
       "      <th>CD8_POSITIVE_CELLS_TOTAL_AREA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>X00936b9285d6b8665ae9122993fb8e91</th>\n",
       "      <td>6.10</td>\n",
       "      <td>4.38</td>\n",
       "      <td>3.07</td>\n",
       "      <td>6.14</td>\n",
       "      <td>4.70</td>\n",
       "      <td>7.52</td>\n",
       "      <td>4.93</td>\n",
       "      <td>8.37</td>\n",
       "      <td>6.21</td>\n",
       "      <td>5.69</td>\n",
       "      <td>...</td>\n",
       "      <td>8.68</td>\n",
       "      <td>7.09</td>\n",
       "      <td>4.94</td>\n",
       "      <td>4.172484</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.928391</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.1931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X105622fadc33f23755ac2df823110aca</th>\n",
       "      <td>5.07</td>\n",
       "      <td>3.33</td>\n",
       "      <td>1.73</td>\n",
       "      <td>5.11</td>\n",
       "      <td>5.62</td>\n",
       "      <td>6.58</td>\n",
       "      <td>4.34</td>\n",
       "      <td>7.42</td>\n",
       "      <td>6.15</td>\n",
       "      <td>4.86</td>\n",
       "      <td>...</td>\n",
       "      <td>6.08</td>\n",
       "      <td>6.56</td>\n",
       "      <td>4.61</td>\n",
       "      <td>16.591375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.122089</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.1214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xe44f39747a8e84b02b4cb24659312144</th>\n",
       "      <td>6.13</td>\n",
       "      <td>4.41</td>\n",
       "      <td>3.23</td>\n",
       "      <td>6.32</td>\n",
       "      <td>5.57</td>\n",
       "      <td>8.02</td>\n",
       "      <td>5.14</td>\n",
       "      <td>7.55</td>\n",
       "      <td>6.87</td>\n",
       "      <td>6.27</td>\n",
       "      <td>...</td>\n",
       "      <td>6.33</td>\n",
       "      <td>7.14</td>\n",
       "      <td>8.42</td>\n",
       "      <td>11.104723</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.616636</td>\n",
       "      <td>80.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.9203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X293dd1284496215e9a0eca9f17a98e7e</th>\n",
       "      <td>5.82</td>\n",
       "      <td>4.30</td>\n",
       "      <td>3.44</td>\n",
       "      <td>6.45</td>\n",
       "      <td>4.86</td>\n",
       "      <td>7.45</td>\n",
       "      <td>4.90</td>\n",
       "      <td>8.39</td>\n",
       "      <td>6.83</td>\n",
       "      <td>5.70</td>\n",
       "      <td>...</td>\n",
       "      <td>6.97</td>\n",
       "      <td>6.73</td>\n",
       "      <td>6.28</td>\n",
       "      <td>14.028748</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.817434</td>\n",
       "      <td>60.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.16</td>\n",
       "      <td>3.1635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X01ed7190ce00862696edbf047b542045</th>\n",
       "      <td>6.15</td>\n",
       "      <td>4.21</td>\n",
       "      <td>3.90</td>\n",
       "      <td>5.93</td>\n",
       "      <td>4.43</td>\n",
       "      <td>7.60</td>\n",
       "      <td>4.74</td>\n",
       "      <td>8.31</td>\n",
       "      <td>6.38</td>\n",
       "      <td>5.94</td>\n",
       "      <td>...</td>\n",
       "      <td>5.67</td>\n",
       "      <td>6.66</td>\n",
       "      <td>4.93</td>\n",
       "      <td>12.418891</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.303864</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.98</td>\n",
       "      <td>2.0708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xc3d410d70dd7359baa40126494fb6765</th>\n",
       "      <td>6.25</td>\n",
       "      <td>3.62</td>\n",
       "      <td>4.80</td>\n",
       "      <td>4.72</td>\n",
       "      <td>5.39</td>\n",
       "      <td>7.01</td>\n",
       "      <td>4.57</td>\n",
       "      <td>6.96</td>\n",
       "      <td>6.26</td>\n",
       "      <td>5.70</td>\n",
       "      <td>...</td>\n",
       "      <td>2.40</td>\n",
       "      <td>6.58</td>\n",
       "      <td>6.59</td>\n",
       "      <td>9.790554</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.552612</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.0089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X50772aa64efb859960b20f8801cd6f58</th>\n",
       "      <td>6.27</td>\n",
       "      <td>3.78</td>\n",
       "      <td>3.98</td>\n",
       "      <td>5.95</td>\n",
       "      <td>4.66</td>\n",
       "      <td>7.18</td>\n",
       "      <td>4.61</td>\n",
       "      <td>8.04</td>\n",
       "      <td>6.62</td>\n",
       "      <td>5.80</td>\n",
       "      <td>...</td>\n",
       "      <td>5.92</td>\n",
       "      <td>6.74</td>\n",
       "      <td>5.48</td>\n",
       "      <td>4.271047</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.672304</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.1775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X91bcd3067a1a7954692d836515e04869</th>\n",
       "      <td>6.12</td>\n",
       "      <td>3.94</td>\n",
       "      <td>3.25</td>\n",
       "      <td>6.09</td>\n",
       "      <td>4.98</td>\n",
       "      <td>7.32</td>\n",
       "      <td>5.02</td>\n",
       "      <td>8.21</td>\n",
       "      <td>6.71</td>\n",
       "      <td>5.89</td>\n",
       "      <td>...</td>\n",
       "      <td>7.84</td>\n",
       "      <td>7.59</td>\n",
       "      <td>7.59</td>\n",
       "      <td>2.496920</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.837849</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.03</td>\n",
       "      <td>3.9642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xc7439a06ffa32b313b0ec1b987b992a2</th>\n",
       "      <td>5.91</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.34</td>\n",
       "      <td>5.80</td>\n",
       "      <td>8.86</td>\n",
       "      <td>8.69</td>\n",
       "      <td>4.52</td>\n",
       "      <td>8.15</td>\n",
       "      <td>5.77</td>\n",
       "      <td>6.85</td>\n",
       "      <td>...</td>\n",
       "      <td>6.81</td>\n",
       "      <td>6.82</td>\n",
       "      <td>5.27</td>\n",
       "      <td>6.505134</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.606825</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.1417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X21a6043653d187f8bbead475d2f49791</th>\n",
       "      <td>6.48</td>\n",
       "      <td>4.32</td>\n",
       "      <td>2.27</td>\n",
       "      <td>6.10</td>\n",
       "      <td>5.13</td>\n",
       "      <td>7.83</td>\n",
       "      <td>5.18</td>\n",
       "      <td>8.34</td>\n",
       "      <td>6.70</td>\n",
       "      <td>6.02</td>\n",
       "      <td>...</td>\n",
       "      <td>6.70</td>\n",
       "      <td>7.98</td>\n",
       "      <td>5.24</td>\n",
       "      <td>5.683778</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.627516</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.1024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>650 rows × 2873 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   NFKB1  TNIP2  AMOT  VASP  SS18L1  SMARCA4  \\\n",
       "id                                                                             \n",
       "X00936b9285d6b8665ae9122993fb8e91   6.10   4.38  3.07  6.14    4.70     7.52   \n",
       "X105622fadc33f23755ac2df823110aca   5.07   3.33  1.73  5.11    5.62     6.58   \n",
       "Xe44f39747a8e84b02b4cb24659312144   6.13   4.41  3.23  6.32    5.57     8.02   \n",
       "X293dd1284496215e9a0eca9f17a98e7e   5.82   4.30  3.44  6.45    4.86     7.45   \n",
       "X01ed7190ce00862696edbf047b542045   6.15   4.21  3.90  5.93    4.43     7.60   \n",
       "...                                  ...    ...   ...   ...     ...      ...   \n",
       "Xc3d410d70dd7359baa40126494fb6765   6.25   3.62  4.80  4.72    5.39     7.01   \n",
       "X50772aa64efb859960b20f8801cd6f58   6.27   3.78  3.98  5.95    4.66     7.18   \n",
       "X91bcd3067a1a7954692d836515e04869   6.12   3.94  3.25  6.09    4.98     7.32   \n",
       "Xc7439a06ffa32b313b0ec1b987b992a2   5.91   3.62  3.34  5.80    8.86     8.69   \n",
       "X21a6043653d187f8bbead475d2f49791   6.48   4.32  2.27  6.10    5.13     7.83   \n",
       "\n",
       "                                   SMURF1  HSPA5  SKIL  UBE2I  ...  SULF2  \\\n",
       "id                                                             ...          \n",
       "X00936b9285d6b8665ae9122993fb8e91    4.93   8.37  6.21   5.69  ...   8.68   \n",
       "X105622fadc33f23755ac2df823110aca    4.34   7.42  6.15   4.86  ...   6.08   \n",
       "Xe44f39747a8e84b02b4cb24659312144    5.14   7.55  6.87   6.27  ...   6.33   \n",
       "X293dd1284496215e9a0eca9f17a98e7e    4.90   8.39  6.83   5.70  ...   6.97   \n",
       "X01ed7190ce00862696edbf047b542045    4.74   8.31  6.38   5.94  ...   5.67   \n",
       "...                                   ...    ...   ...    ...  ...    ...   \n",
       "Xc3d410d70dd7359baa40126494fb6765    4.57   6.96  6.26   5.70  ...   2.40   \n",
       "X50772aa64efb859960b20f8801cd6f58    4.61   8.04  6.62   5.80  ...   5.92   \n",
       "X91bcd3067a1a7954692d836515e04869    5.02   8.21  6.71   5.89  ...   7.84   \n",
       "Xc7439a06ffa32b313b0ec1b987b992a2    4.52   8.15  5.77   6.85  ...   6.81   \n",
       "X21a6043653d187f8bbead475d2f49791    5.18   8.34  6.70   6.02  ...   6.70   \n",
       "\n",
       "                                   CD276  TIPARP      PFS_P  PFS_P_CNSR  \\\n",
       "id                                                                        \n",
       "X00936b9285d6b8665ae9122993fb8e91   7.09    4.94   4.172484         0.0   \n",
       "X105622fadc33f23755ac2df823110aca   6.56    4.61  16.591375         1.0   \n",
       "Xe44f39747a8e84b02b4cb24659312144   7.14    8.42  11.104723         0.0   \n",
       "X293dd1284496215e9a0eca9f17a98e7e   6.73    6.28  14.028748         1.0   \n",
       "X01ed7190ce00862696edbf047b542045   6.66    4.93  12.418891         0.0   \n",
       "...                                  ...     ...        ...         ...   \n",
       "Xc3d410d70dd7359baa40126494fb6765   6.58    6.59   9.790554         1.0   \n",
       "X50772aa64efb859960b20f8801cd6f58   6.74    5.48   4.271047         0.0   \n",
       "X91bcd3067a1a7954692d836515e04869   7.59    7.59   2.496920         0.0   \n",
       "Xc7439a06ffa32b313b0ec1b987b992a2   6.82    5.27   6.505134         1.0   \n",
       "X21a6043653d187f8bbead475d2f49791   7.98    5.24   5.683778         1.0   \n",
       "\n",
       "                                        MATH  \\\n",
       "id                                             \n",
       "X00936b9285d6b8665ae9122993fb8e91  17.928391   \n",
       "X105622fadc33f23755ac2df823110aca  16.122089   \n",
       "Xe44f39747a8e84b02b4cb24659312144  23.616636   \n",
       "X293dd1284496215e9a0eca9f17a98e7e  24.817434   \n",
       "X01ed7190ce00862696edbf047b542045  19.303864   \n",
       "...                                      ...   \n",
       "Xc3d410d70dd7359baa40126494fb6765  24.552612   \n",
       "X50772aa64efb859960b20f8801cd6f58  15.672304   \n",
       "X91bcd3067a1a7954692d836515e04869  27.837849   \n",
       "Xc7439a06ffa32b313b0ec1b987b992a2  26.606825   \n",
       "X21a6043653d187f8bbead475d2f49791  17.627516   \n",
       "\n",
       "                                   HE_TUMOR_CELL_CONTENT_IN_TUMOR_AREA  \\\n",
       "id                                                                       \n",
       "X00936b9285d6b8665ae9122993fb8e91                                 70.0   \n",
       "X105622fadc33f23755ac2df823110aca                                 85.0   \n",
       "Xe44f39747a8e84b02b4cb24659312144                                 80.0   \n",
       "X293dd1284496215e9a0eca9f17a98e7e                                 60.0   \n",
       "X01ed7190ce00862696edbf047b542045                                 80.0   \n",
       "...                                                                ...   \n",
       "Xc3d410d70dd7359baa40126494fb6765                                 75.0   \n",
       "X50772aa64efb859960b20f8801cd6f58                                 75.0   \n",
       "X91bcd3067a1a7954692d836515e04869                                 50.0   \n",
       "Xc7439a06ffa32b313b0ec1b987b992a2                                 80.0   \n",
       "X21a6043653d187f8bbead475d2f49791                                 70.0   \n",
       "\n",
       "                                   PD-L1_TOTAL_IMMUNE_CELLS_PER_TUMOR_AREA  \\\n",
       "id                                                                           \n",
       "X00936b9285d6b8665ae9122993fb8e91                                      0.0   \n",
       "X105622fadc33f23755ac2df823110aca                                      1.0   \n",
       "Xe44f39747a8e84b02b4cb24659312144                                      5.0   \n",
       "X293dd1284496215e9a0eca9f17a98e7e                                      5.0   \n",
       "X01ed7190ce00862696edbf047b542045                                      2.0   \n",
       "...                                                                    ...   \n",
       "Xc3d410d70dd7359baa40126494fb6765                                      0.0   \n",
       "X50772aa64efb859960b20f8801cd6f58                                      1.0   \n",
       "X91bcd3067a1a7954692d836515e04869                                      1.0   \n",
       "Xc7439a06ffa32b313b0ec1b987b992a2                                      1.0   \n",
       "X21a6043653d187f8bbead475d2f49791                                      0.0   \n",
       "\n",
       "                                   CD8_POSITIVE_CELLS_TUMOR_CENTER  \\\n",
       "id                                                                   \n",
       "X00936b9285d6b8665ae9122993fb8e91                             0.08   \n",
       "X105622fadc33f23755ac2df823110aca                             0.12   \n",
       "Xe44f39747a8e84b02b4cb24659312144                             0.92   \n",
       "X293dd1284496215e9a0eca9f17a98e7e                             3.16   \n",
       "X01ed7190ce00862696edbf047b542045                             1.98   \n",
       "...                                                            ...   \n",
       "Xc3d410d70dd7359baa40126494fb6765                             1.01   \n",
       "X50772aa64efb859960b20f8801cd6f58                             1.10   \n",
       "X91bcd3067a1a7954692d836515e04869                             4.03   \n",
       "Xc7439a06ffa32b313b0ec1b987b992a2                             0.14   \n",
       "X21a6043653d187f8bbead475d2f49791                             3.10   \n",
       "\n",
       "                                   CD8_POSITIVE_CELLS_TOTAL_AREA  \n",
       "id                                                                \n",
       "X00936b9285d6b8665ae9122993fb8e91                         0.1931  \n",
       "X105622fadc33f23755ac2df823110aca                         0.1214  \n",
       "Xe44f39747a8e84b02b4cb24659312144                         0.9203  \n",
       "X293dd1284496215e9a0eca9f17a98e7e                         3.1635  \n",
       "X01ed7190ce00862696edbf047b542045                         2.0708  \n",
       "...                                                          ...  \n",
       "Xc3d410d70dd7359baa40126494fb6765                         1.0089  \n",
       "X50772aa64efb859960b20f8801cd6f58                         1.1775  \n",
       "X91bcd3067a1a7954692d836515e04869                         3.9642  \n",
       "Xc7439a06ffa32b313b0ec1b987b992a2                         0.1417  \n",
       "X21a6043653d187f8bbead475d2f49791                         3.1024  \n",
       "\n",
       "[650 rows x 2873 columns]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_directory = os.getcwd()\n",
    "\n",
    "somepath = os.path.abspath(\n",
    "    os.path.join(current_directory, '..', 'Data', 'RNA_dataset_tabular_R3.csv'))\n",
    "\n",
    "# expression data\n",
    "tabular_data = pd.read_csv(somepath, sep = ',', index_col = 0)\n",
    "tabular_data = tabular_data.astype('float32')\n",
    "gene_data = tabular_data\n",
    "gene_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "89eeeecb-ed7d-4b37-b588-b9359a06f7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cli_vars = ['PFS_P', 'PFS_P_CNSR', 'MATH', 'HE_TUMOR_CELL_CONTENT_IN_TUMOR_AREA', 'PD-L1_TOTAL_IMMUNE_CELLS_PER_TUMOR_AREA', 'CD8_POSITIVE_CELLS_TUMOR_CENTER', 'CD8_POSITIVE_CELLS_TOTAL_AREA']\n",
    "gene_data = tabular_data.drop(columns = cli_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "224606a8-1923-444b-846e-6c25fe97f54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxVal = max([x for L in gene_data.values for x in L])\n",
    "X_normalized = gene_data / maxVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "e700c95f-68c2-4f4f-b0d6-44312ccf723f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NFKB1</th>\n",
       "      <th>TNIP2</th>\n",
       "      <th>AMOT</th>\n",
       "      <th>VASP</th>\n",
       "      <th>SS18L1</th>\n",
       "      <th>SMARCA4</th>\n",
       "      <th>SMURF1</th>\n",
       "      <th>HSPA5</th>\n",
       "      <th>SKIL</th>\n",
       "      <th>UBE2I</th>\n",
       "      <th>...</th>\n",
       "      <th>SLC22A3</th>\n",
       "      <th>SPAG16</th>\n",
       "      <th>HTATIP2</th>\n",
       "      <th>SLC17A1</th>\n",
       "      <th>MGST2</th>\n",
       "      <th>CHPT1</th>\n",
       "      <th>STK17A</th>\n",
       "      <th>SULF2</th>\n",
       "      <th>CD276</th>\n",
       "      <th>TIPARP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>X00936b9285d6b8665ae9122993fb8e91</th>\n",
       "      <td>0.395078</td>\n",
       "      <td>0.283679</td>\n",
       "      <td>0.198834</td>\n",
       "      <td>0.397668</td>\n",
       "      <td>0.304404</td>\n",
       "      <td>0.487047</td>\n",
       "      <td>0.319301</td>\n",
       "      <td>0.542098</td>\n",
       "      <td>0.402202</td>\n",
       "      <td>0.368523</td>\n",
       "      <td>...</td>\n",
       "      <td>0.163860</td>\n",
       "      <td>0.281736</td>\n",
       "      <td>0.288212</td>\n",
       "      <td>0.289508</td>\n",
       "      <td>0.457902</td>\n",
       "      <td>0.338731</td>\n",
       "      <td>0.264249</td>\n",
       "      <td>0.562176</td>\n",
       "      <td>0.459197</td>\n",
       "      <td>0.319948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X105622fadc33f23755ac2df823110aca</th>\n",
       "      <td>0.328368</td>\n",
       "      <td>0.215674</td>\n",
       "      <td>0.112047</td>\n",
       "      <td>0.330959</td>\n",
       "      <td>0.363990</td>\n",
       "      <td>0.426166</td>\n",
       "      <td>0.281088</td>\n",
       "      <td>0.480570</td>\n",
       "      <td>0.398316</td>\n",
       "      <td>0.314767</td>\n",
       "      <td>...</td>\n",
       "      <td>0.371762</td>\n",
       "      <td>0.287565</td>\n",
       "      <td>0.308290</td>\n",
       "      <td>0.288212</td>\n",
       "      <td>0.479275</td>\n",
       "      <td>0.443005</td>\n",
       "      <td>0.183938</td>\n",
       "      <td>0.393782</td>\n",
       "      <td>0.424870</td>\n",
       "      <td>0.298575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xe44f39747a8e84b02b4cb24659312144</th>\n",
       "      <td>0.397021</td>\n",
       "      <td>0.285622</td>\n",
       "      <td>0.209197</td>\n",
       "      <td>0.409326</td>\n",
       "      <td>0.360751</td>\n",
       "      <td>0.519430</td>\n",
       "      <td>0.332902</td>\n",
       "      <td>0.488990</td>\n",
       "      <td>0.444948</td>\n",
       "      <td>0.406088</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300518</td>\n",
       "      <td>0.264249</td>\n",
       "      <td>0.299870</td>\n",
       "      <td>0.190415</td>\n",
       "      <td>0.431347</td>\n",
       "      <td>0.376295</td>\n",
       "      <td>0.269430</td>\n",
       "      <td>0.409974</td>\n",
       "      <td>0.462435</td>\n",
       "      <td>0.545337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X293dd1284496215e9a0eca9f17a98e7e</th>\n",
       "      <td>0.376943</td>\n",
       "      <td>0.278497</td>\n",
       "      <td>0.222798</td>\n",
       "      <td>0.417746</td>\n",
       "      <td>0.314767</td>\n",
       "      <td>0.482513</td>\n",
       "      <td>0.317358</td>\n",
       "      <td>0.543394</td>\n",
       "      <td>0.442358</td>\n",
       "      <td>0.369171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.292746</td>\n",
       "      <td>0.306995</td>\n",
       "      <td>0.318653</td>\n",
       "      <td>0.053756</td>\n",
       "      <td>0.431995</td>\n",
       "      <td>0.341321</td>\n",
       "      <td>0.266839</td>\n",
       "      <td>0.451425</td>\n",
       "      <td>0.435881</td>\n",
       "      <td>0.406736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X01ed7190ce00862696edbf047b542045</th>\n",
       "      <td>0.398316</td>\n",
       "      <td>0.272668</td>\n",
       "      <td>0.252591</td>\n",
       "      <td>0.384067</td>\n",
       "      <td>0.286917</td>\n",
       "      <td>0.492228</td>\n",
       "      <td>0.306995</td>\n",
       "      <td>0.538212</td>\n",
       "      <td>0.413212</td>\n",
       "      <td>0.384715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127591</td>\n",
       "      <td>0.347798</td>\n",
       "      <td>0.361399</td>\n",
       "      <td>0.433938</td>\n",
       "      <td>0.422927</td>\n",
       "      <td>0.378238</td>\n",
       "      <td>0.281736</td>\n",
       "      <td>0.367228</td>\n",
       "      <td>0.431347</td>\n",
       "      <td>0.319301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xc3d410d70dd7359baa40126494fb6765</th>\n",
       "      <td>0.404793</td>\n",
       "      <td>0.234456</td>\n",
       "      <td>0.310881</td>\n",
       "      <td>0.305699</td>\n",
       "      <td>0.349093</td>\n",
       "      <td>0.454016</td>\n",
       "      <td>0.295984</td>\n",
       "      <td>0.450777</td>\n",
       "      <td>0.405440</td>\n",
       "      <td>0.369171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.370466</td>\n",
       "      <td>0.457902</td>\n",
       "      <td>0.306995</td>\n",
       "      <td>0.448187</td>\n",
       "      <td>0.367228</td>\n",
       "      <td>0.488990</td>\n",
       "      <td>0.150259</td>\n",
       "      <td>0.155440</td>\n",
       "      <td>0.426166</td>\n",
       "      <td>0.426813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X50772aa64efb859960b20f8801cd6f58</th>\n",
       "      <td>0.406088</td>\n",
       "      <td>0.244819</td>\n",
       "      <td>0.257772</td>\n",
       "      <td>0.385363</td>\n",
       "      <td>0.301813</td>\n",
       "      <td>0.465026</td>\n",
       "      <td>0.298575</td>\n",
       "      <td>0.520725</td>\n",
       "      <td>0.428756</td>\n",
       "      <td>0.375648</td>\n",
       "      <td>...</td>\n",
       "      <td>0.312824</td>\n",
       "      <td>0.372409</td>\n",
       "      <td>0.360751</td>\n",
       "      <td>0.505829</td>\n",
       "      <td>0.470207</td>\n",
       "      <td>0.398316</td>\n",
       "      <td>0.227979</td>\n",
       "      <td>0.383420</td>\n",
       "      <td>0.436529</td>\n",
       "      <td>0.354922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X91bcd3067a1a7954692d836515e04869</th>\n",
       "      <td>0.396373</td>\n",
       "      <td>0.255181</td>\n",
       "      <td>0.210492</td>\n",
       "      <td>0.394430</td>\n",
       "      <td>0.322539</td>\n",
       "      <td>0.474093</td>\n",
       "      <td>0.325130</td>\n",
       "      <td>0.531736</td>\n",
       "      <td>0.434586</td>\n",
       "      <td>0.381477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199482</td>\n",
       "      <td>0.313472</td>\n",
       "      <td>0.338731</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>0.413212</td>\n",
       "      <td>0.336788</td>\n",
       "      <td>0.262306</td>\n",
       "      <td>0.507772</td>\n",
       "      <td>0.491580</td>\n",
       "      <td>0.491580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xc7439a06ffa32b313b0ec1b987b992a2</th>\n",
       "      <td>0.382772</td>\n",
       "      <td>0.234456</td>\n",
       "      <td>0.216321</td>\n",
       "      <td>0.375648</td>\n",
       "      <td>0.573834</td>\n",
       "      <td>0.562824</td>\n",
       "      <td>0.292746</td>\n",
       "      <td>0.527850</td>\n",
       "      <td>0.373705</td>\n",
       "      <td>0.443653</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060881</td>\n",
       "      <td>0.389896</td>\n",
       "      <td>0.261658</td>\n",
       "      <td>0.473446</td>\n",
       "      <td>0.437824</td>\n",
       "      <td>0.461140</td>\n",
       "      <td>0.210492</td>\n",
       "      <td>0.441062</td>\n",
       "      <td>0.441710</td>\n",
       "      <td>0.341321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X21a6043653d187f8bbead475d2f49791</th>\n",
       "      <td>0.419689</td>\n",
       "      <td>0.279793</td>\n",
       "      <td>0.147021</td>\n",
       "      <td>0.395078</td>\n",
       "      <td>0.332254</td>\n",
       "      <td>0.507124</td>\n",
       "      <td>0.335492</td>\n",
       "      <td>0.540155</td>\n",
       "      <td>0.433938</td>\n",
       "      <td>0.389896</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055699</td>\n",
       "      <td>0.417746</td>\n",
       "      <td>0.360104</td>\n",
       "      <td>0.593912</td>\n",
       "      <td>0.455959</td>\n",
       "      <td>0.353627</td>\n",
       "      <td>0.265544</td>\n",
       "      <td>0.433938</td>\n",
       "      <td>0.516839</td>\n",
       "      <td>0.339378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>650 rows × 2866 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      NFKB1     TNIP2      AMOT      VASP  \\\n",
       "id                                                                          \n",
       "X00936b9285d6b8665ae9122993fb8e91  0.395078  0.283679  0.198834  0.397668   \n",
       "X105622fadc33f23755ac2df823110aca  0.328368  0.215674  0.112047  0.330959   \n",
       "Xe44f39747a8e84b02b4cb24659312144  0.397021  0.285622  0.209197  0.409326   \n",
       "X293dd1284496215e9a0eca9f17a98e7e  0.376943  0.278497  0.222798  0.417746   \n",
       "X01ed7190ce00862696edbf047b542045  0.398316  0.272668  0.252591  0.384067   \n",
       "...                                     ...       ...       ...       ...   \n",
       "Xc3d410d70dd7359baa40126494fb6765  0.404793  0.234456  0.310881  0.305699   \n",
       "X50772aa64efb859960b20f8801cd6f58  0.406088  0.244819  0.257772  0.385363   \n",
       "X91bcd3067a1a7954692d836515e04869  0.396373  0.255181  0.210492  0.394430   \n",
       "Xc7439a06ffa32b313b0ec1b987b992a2  0.382772  0.234456  0.216321  0.375648   \n",
       "X21a6043653d187f8bbead475d2f49791  0.419689  0.279793  0.147021  0.395078   \n",
       "\n",
       "                                     SS18L1   SMARCA4    SMURF1     HSPA5  \\\n",
       "id                                                                          \n",
       "X00936b9285d6b8665ae9122993fb8e91  0.304404  0.487047  0.319301  0.542098   \n",
       "X105622fadc33f23755ac2df823110aca  0.363990  0.426166  0.281088  0.480570   \n",
       "Xe44f39747a8e84b02b4cb24659312144  0.360751  0.519430  0.332902  0.488990   \n",
       "X293dd1284496215e9a0eca9f17a98e7e  0.314767  0.482513  0.317358  0.543394   \n",
       "X01ed7190ce00862696edbf047b542045  0.286917  0.492228  0.306995  0.538212   \n",
       "...                                     ...       ...       ...       ...   \n",
       "Xc3d410d70dd7359baa40126494fb6765  0.349093  0.454016  0.295984  0.450777   \n",
       "X50772aa64efb859960b20f8801cd6f58  0.301813  0.465026  0.298575  0.520725   \n",
       "X91bcd3067a1a7954692d836515e04869  0.322539  0.474093  0.325130  0.531736   \n",
       "Xc7439a06ffa32b313b0ec1b987b992a2  0.573834  0.562824  0.292746  0.527850   \n",
       "X21a6043653d187f8bbead475d2f49791  0.332254  0.507124  0.335492  0.540155   \n",
       "\n",
       "                                       SKIL     UBE2I  ...   SLC22A3  \\\n",
       "id                                                     ...             \n",
       "X00936b9285d6b8665ae9122993fb8e91  0.402202  0.368523  ...  0.163860   \n",
       "X105622fadc33f23755ac2df823110aca  0.398316  0.314767  ...  0.371762   \n",
       "Xe44f39747a8e84b02b4cb24659312144  0.444948  0.406088  ...  0.300518   \n",
       "X293dd1284496215e9a0eca9f17a98e7e  0.442358  0.369171  ...  0.292746   \n",
       "X01ed7190ce00862696edbf047b542045  0.413212  0.384715  ...  0.127591   \n",
       "...                                     ...       ...  ...       ...   \n",
       "Xc3d410d70dd7359baa40126494fb6765  0.405440  0.369171  ...  0.370466   \n",
       "X50772aa64efb859960b20f8801cd6f58  0.428756  0.375648  ...  0.312824   \n",
       "X91bcd3067a1a7954692d836515e04869  0.434586  0.381477  ...  0.199482   \n",
       "Xc7439a06ffa32b313b0ec1b987b992a2  0.373705  0.443653  ...  0.060881   \n",
       "X21a6043653d187f8bbead475d2f49791  0.433938  0.389896  ...  0.055699   \n",
       "\n",
       "                                     SPAG16   HTATIP2   SLC17A1     MGST2  \\\n",
       "id                                                                          \n",
       "X00936b9285d6b8665ae9122993fb8e91  0.281736  0.288212  0.289508  0.457902   \n",
       "X105622fadc33f23755ac2df823110aca  0.287565  0.308290  0.288212  0.479275   \n",
       "Xe44f39747a8e84b02b4cb24659312144  0.264249  0.299870  0.190415  0.431347   \n",
       "X293dd1284496215e9a0eca9f17a98e7e  0.306995  0.318653  0.053756  0.431995   \n",
       "X01ed7190ce00862696edbf047b542045  0.347798  0.361399  0.433938  0.422927   \n",
       "...                                     ...       ...       ...       ...   \n",
       "Xc3d410d70dd7359baa40126494fb6765  0.457902  0.306995  0.448187  0.367228   \n",
       "X50772aa64efb859960b20f8801cd6f58  0.372409  0.360751  0.505829  0.470207   \n",
       "X91bcd3067a1a7954692d836515e04869  0.313472  0.338731  0.000648  0.413212   \n",
       "Xc7439a06ffa32b313b0ec1b987b992a2  0.389896  0.261658  0.473446  0.437824   \n",
       "X21a6043653d187f8bbead475d2f49791  0.417746  0.360104  0.593912  0.455959   \n",
       "\n",
       "                                      CHPT1    STK17A     SULF2     CD276  \\\n",
       "id                                                                          \n",
       "X00936b9285d6b8665ae9122993fb8e91  0.338731  0.264249  0.562176  0.459197   \n",
       "X105622fadc33f23755ac2df823110aca  0.443005  0.183938  0.393782  0.424870   \n",
       "Xe44f39747a8e84b02b4cb24659312144  0.376295  0.269430  0.409974  0.462435   \n",
       "X293dd1284496215e9a0eca9f17a98e7e  0.341321  0.266839  0.451425  0.435881   \n",
       "X01ed7190ce00862696edbf047b542045  0.378238  0.281736  0.367228  0.431347   \n",
       "...                                     ...       ...       ...       ...   \n",
       "Xc3d410d70dd7359baa40126494fb6765  0.488990  0.150259  0.155440  0.426166   \n",
       "X50772aa64efb859960b20f8801cd6f58  0.398316  0.227979  0.383420  0.436529   \n",
       "X91bcd3067a1a7954692d836515e04869  0.336788  0.262306  0.507772  0.491580   \n",
       "Xc7439a06ffa32b313b0ec1b987b992a2  0.461140  0.210492  0.441062  0.441710   \n",
       "X21a6043653d187f8bbead475d2f49791  0.353627  0.265544  0.433938  0.516839   \n",
       "\n",
       "                                     TIPARP  \n",
       "id                                           \n",
       "X00936b9285d6b8665ae9122993fb8e91  0.319948  \n",
       "X105622fadc33f23755ac2df823110aca  0.298575  \n",
       "Xe44f39747a8e84b02b4cb24659312144  0.545337  \n",
       "X293dd1284496215e9a0eca9f17a98e7e  0.406736  \n",
       "X01ed7190ce00862696edbf047b542045  0.319301  \n",
       "...                                     ...  \n",
       "Xc3d410d70dd7359baa40126494fb6765  0.426813  \n",
       "X50772aa64efb859960b20f8801cd6f58  0.354922  \n",
       "X91bcd3067a1a7954692d836515e04869  0.491580  \n",
       "Xc7439a06ffa32b313b0ec1b987b992a2  0.341321  \n",
       "X21a6043653d187f8bbead475d2f49791  0.339378  \n",
       "\n",
       "[650 rows x 2866 columns]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "ea96e5f7-87db-4260-b726-71225de3306f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "torch_tensor = torch.tensor(X_normalized.values)\n",
    "\n",
    "data = CustomDataset(torch_tensor, [1] * len(torch_tensor), [2] * len(torch_tensor))\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = list(DataLoader(data, batch_size=batch_size, shuffle=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "01d3c0a8-60bf-4a57-8c87-3b410045eda1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2.])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = list(train_loader)\n",
    "res = torch.tensor([])\n",
    "for x in X:\n",
    "    res = torch.cat((res, x[2]), dim=0)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ab80194c-35d4-4143-8b57-69e99da559f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Minimal Working Example AE with input dim:  2866\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.4127, 0.3174, 0.9258,  ..., 0.3901, 0.5520, 0.3169],\n",
       "        [0.4575, 0.3279, 0.6706,  ..., 0.9447, 0.7058, 0.4176],\n",
       "        [0.4127, 0.3884, 0.6172,  ..., 0.2966, 0.3303, 0.4176],\n",
       "        ...,\n",
       "        [0.3089, 0.4147, 0.4174,  ..., 0.7215, 0.4200, 0.9184],\n",
       "        [0.4127, 0.4273, 0.4162,  ..., 0.7860, 0.4790, 0.3998],\n",
       "        [0.7091, 0.5397, 0.3998,  ..., 0.4216, 0.2475, 0.4176]],\n",
       "       grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tab = MWE_AE(2866, 50)\n",
    "lat = model_tab(res)\n",
    "lat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278d236d-e445-47dc-add9-df8872978673",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fda5e2a-e444-437b-9a62-9486ad3e8ffb",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13379fe5-383d-4276-b5a9-e6ebd5b5565a",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf18b95-03d0-40ae-9e45-88cdb712890d",
   "metadata": {},
   "source": [
    "### GRAPH SIDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3ab1a719-b8a9-43fd-a502-8bc9be0c172a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "somepath = os.path.abspath(\n",
    "    os.path.join(current_directory, '..', 'Data', 'RNA_dataset_graph_R3.pkl'))\n",
    "\n",
    "with open(somepath, 'rb') as f:\n",
    "    loaded_object = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1ed4b184-99fe-4b10-bc73-1da398dbeafd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.1000, 4.3800, 3.0700,  ..., 8.6800, 7.0900, 4.9400],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = loaded_object[0]\n",
    "features = []\n",
    "for node, attr in G.nodes(data = True):\n",
    "    features += [attr['node_attr']]\n",
    "features = torch.tensor(features)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "8cec6e04-76c3-4eb0-92f5-12a9a9abc684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2866], edge_index=[2, 90932])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "data = None\n",
    "\n",
    "G = loaded_object[0]\n",
    "# we enumerate each node in a dict\n",
    "node_to_index = {node: idx for idx, node in enumerate(G.nodes())}\n",
    "\n",
    "edge_index = torch.tensor([(node_to_index[edge[0]], node_to_index[edge[1]]) for edge in G.edges()] +\n",
    "                 [(node_to_index[edge[1]], node_to_index[edge[0]]) for edge in G.edges()]).t().contiguous()\n",
    "data = Data(x= features, edge_index = edge_index)\n",
    "data.validate(raise_on_error=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "dbed410c-7db2-4e76-814f-73e6e48a7327",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_all_graph_data(graphs):\n",
    "    D = []\n",
    "    # edges are the same for all graphs so we only need to compute this once.\n",
    "    G = graphs[0]\n",
    "    node_to_index = {node: idx for idx, node in enumerate(G.nodes())}\n",
    "\n",
    "    edge_index = torch.tensor([(node_to_index[edge[0]], node_to_index[edge[1]]) for edge in G.edges()] +\n",
    "                 [(node_to_index[edge[1]], node_to_index[edge[0]]) for edge in G.edges()]).t().contiguous()\n",
    "    \n",
    "    for g in graphs:\n",
    "        features = []\n",
    "        for node, attr in g.nodes(data = True):\n",
    "            features += [[float(attr['node_attr'])]]\n",
    "        features = torch.tensor(features)\n",
    "        d = Data(x = features, edge_index = edge_index)\n",
    "        d.validate(raise_on_error=True)\n",
    "        D += [d]\n",
    "    return D\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7217b988-82c7-428b-87af-ddf5f714de06",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = collect_all_graph_data(loaded_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "35ca7e1f-56a7-4de9-9588-c7aea65c8244",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[DataBatch(x=[183424, 1], edge_index=[2, 5819648], batch=[183424], ptr=[65]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])],\n",
       " [DataBatch(x=[183424, 1], edge_index=[2, 5819648], batch=[183424], ptr=[65]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])],\n",
       " [DataBatch(x=[183424, 1], edge_index=[2, 5819648], batch=[183424], ptr=[65]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])],\n",
       " [DataBatch(x=[183424, 1], edge_index=[2, 5819648], batch=[183424], ptr=[65]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])],\n",
       " [DataBatch(x=[183424, 1], edge_index=[2, 5819648], batch=[183424], ptr=[65]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])],\n",
       " [DataBatch(x=[183424, 1], edge_index=[2, 5819648], batch=[183424], ptr=[65]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])],\n",
       " [DataBatch(x=[183424, 1], edge_index=[2, 5819648], batch=[183424], ptr=[65]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])],\n",
       " [DataBatch(x=[183424, 1], edge_index=[2, 5819648], batch=[183424], ptr=[65]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])],\n",
       " [DataBatch(x=[183424, 1], edge_index=[2, 5819648], batch=[183424], ptr=[65]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])],\n",
       " [DataBatch(x=[183424, 1], edge_index=[2, 5819648], batch=[183424], ptr=[65]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])],\n",
       " [DataBatch(x=[28660, 1], edge_index=[2, 909320], batch=[28660], ptr=[11]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2])]]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "custom_dataset = CustomDataset(X, [1] * len(X), [2] * len(X))\n",
    "    \n",
    "loader = list(DataLoader(custom_dataset, batch_size=64, shuffle=False))\n",
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "c3300c24-e3fc-497d-b892-e556cba68660",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(loader)\n",
    "dim = 0\n",
    "res = []\n",
    "for x in X:\n",
    "    res += [x[dim]]\n",
    "z = list(DataLoader(res, batch_size = len(res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "fd818d63-c4dc-484f-b46d-2a38aaa70820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[1862900, 1], edge_index=[2, 59105800], batch=[1862900])"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "0db0849f-5627-4868-9f38-f840ad5d3b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9231, 0.7012, 0.8368,  ..., 0.7934, 0.7635, 0.6901],\n",
       "        [0.9042, 0.6851, 0.8098,  ..., 0.7188, 0.7471, 0.6788],\n",
       "        [0.9257, 0.7095, 0.8421,  ..., 0.7359, 0.7640, 0.7821],\n",
       "        ...,\n",
       "        [0.9251, 0.7017, 0.8335,  ..., 0.7628, 0.7763, 0.7630],\n",
       "        [0.9216, 0.6988, 0.8443,  ..., 0.7445, 0.7536, 0.6975],\n",
       "        [0.9272, 0.7061, 0.8407,  ..., 0.7397, 0.7848, 0.7020]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GNNExample(1, 2866, 650, 50, 650)\n",
    "lat = model(z)\n",
    "lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e914360e-5178-4160-9461-2701cfa0524e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "650"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56fb6c3-0b5e-4068-8638-a2b7c5f9f37d",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c34b3b-c3e2-4d25-984e-b8ebb80b9539",
   "metadata": {},
   "source": [
    "## PROOF THAT DATA LOADER CAN ACTUALLY HANDLE DATA BATCHES!!\n",
    "\n",
    "The problem here was that if we already have a dataloader with batches of size 32, if we were to unroll these batches to make a bigger dataloader without batches (so all data in one batch), how would this be done? Luckily, the library accounts for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "29357e15-d03f-403c-aadf-f300fb7e428d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph 1:\n",
      "Data(edge_index=[2, 2])\n",
      "Graph 2:\n",
      "Data(edge_index=[2, 2])\n",
      "Graph 3:\n",
      "Data(edge_index=[2, 2])\n",
      "First data loader\n",
      "DataBatch(edge_index=[2, 4], batch=[4], ptr=[3])\n",
      "DataBatch(edge_index=[2, 2], batch=[2], ptr=[2])\n",
      "Second data loader\n",
      "DataBatch(edge_index=[2, 6], batch=[6])\n",
      "tensor([[0, 1, 2, 3, 4, 5],\n",
      "        [1, 0, 3, 2, 5, 4]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_geometric.data as data\n",
    "\n",
    "# Define the edges for the first graph\n",
    "edges1 = torch.tensor([[0,1], [1,0]])\n",
    "\n",
    "\n",
    "# Create data objects for each graph\n",
    "graph1 = data.Data(edge_index=edges1)\n",
    "graph2 = data.Data(edge_index=edges1)\n",
    "graph3 = data.Data(edge_index=edges1)\n",
    "\n",
    "# Print the graphs\n",
    "print(\"Graph 1:\")\n",
    "print(graph1)\n",
    "print(\"Graph 2:\")\n",
    "print(graph2)\n",
    "print(\"Graph 3:\")\n",
    "print(graph3)\n",
    "\n",
    "x = [graph1, graph2, graph3]\n",
    "\n",
    "print(\"First data loader\")\n",
    "d = DataLoader(x, batch_size = 2)\n",
    "\n",
    "xs = []\n",
    "for i in d:\n",
    "    print(i)\n",
    "    xs +=[i]\n",
    "\n",
    "print(\"Second data loader\")\n",
    "d2 = DataLoader(xs, batch_size = 3)\n",
    "for i in d2:\n",
    "    print(i)\n",
    "    print(i.edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a5c792-06f9-4c97-ad12-2cf24f7e5a4d",
   "metadata": {},
   "source": [
    "------------------\n",
    "---------------------\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5edaea33-fbce-48a8-b2f3-a790764df602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [2.],\n",
      "        [2.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import GCNConv, SimpleConv\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Define the adjacency matrix of the graph\n",
    "edge_index = torch.tensor([[0,1,1,2], [1,0,2,1]], dtype=torch.long)\n",
    "\n",
    "# Define the features for each node\n",
    "x = torch.tensor([[1], [2], [3]], dtype=torch.float)\n",
    "\n",
    "# Define the GCNConv layer\n",
    "in_channels = 1  # Number of input features per node\n",
    "out_channels = 1  # Number of output features per node\n",
    "conv = SimpleConv(aggr = \"median\", combine_root = \"self_loop\")\n",
    "\n",
    "# Process the graph through the GCNConv layer\n",
    "x = conv(x, edge_index)\n",
    "\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8c35226-efca-49f9-b239-c5544e5896cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle \n",
    "import torch\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "somepath = os.path.abspath(\n",
    "    os.path.join(current_directory, '..', 'Data', 'RNA_dataset_graph_R3.pkl'))\n",
    "\n",
    "with open(somepath, 'rb') as f:\n",
    "    loaded_object = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "151b090d-3711-4a97-940b-d16e6b5d28c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.1000],\n",
       "        [4.3800],\n",
       "        [3.0700],\n",
       "        ...,\n",
       "        [8.6800],\n",
       "        [7.0900],\n",
       "        [4.9400]], dtype=torch.float64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = loaded_object[0]\n",
    "features = []\n",
    "for node, attr in G.nodes(data = True):\n",
    "    features += [[attr['node_attr']]]\n",
    "features = torch.tensor(features)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "50a78ed9-0a05-456f-91d2-da2d1235b8fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2866, 1], edge_index=[2, 90932])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "data = None\n",
    "\n",
    "G = loaded_object[0]\n",
    "# we enumerate each node in a dict\n",
    "node_to_index = {node: idx for idx, node in enumerate(G.nodes())}\n",
    "\n",
    "edge_index = torch.tensor([(node_to_index[edge[0]], node_to_index[edge[1]]) for edge in G.edges()] +\n",
    "                 [(node_to_index[edge[1]], node_to_index[edge[0]]) for edge in G.edges()]).t().contiguous()\n",
    "data = Data(x= features, edge_index = edge_index)\n",
    "data.validate(raise_on_error=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7ec188f5-74a6-4a74-a72a-06c372485f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6.3951],\n",
      "        [6.3043],\n",
      "        [5.6857],\n",
      "        ...,\n",
      "        [6.8600],\n",
      "        [6.8500],\n",
      "        [5.9700]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "conv = SimpleConv(aggr = \"mean\", combine_root = \"self_loop\")\n",
    "\n",
    "# Process the graph through the GCNConv layer\n",
    "x = conv(data.x, data.edge_index)\n",
    "\n",
    "print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
