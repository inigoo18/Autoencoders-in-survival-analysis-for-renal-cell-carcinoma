{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "176c13f7-2cd0-4338-add4-778da779634f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import mygene\n",
    "import torch\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e7cc858-246f-462b-8f93-661b2b46f0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, Sequential\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "from torch_geometric.nn import GAE\n",
    "from torch_geometric.data import Data, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4c3cfe5-9ca0-46ae-b099-20dd402921f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Type\n",
    "\n",
    "import torch\n",
    "import torch_geometric\n",
    "\n",
    "from torch.nn import Linear, ReLU,Dropout\n",
    "from torch_geometric.nn import Sequential, GCNConv, TopKPooling\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class GNNExample(nn.Module):\n",
    "    def __init__(self, num_features, input_dim, num_samples, L, batch_size):\n",
    "        super(GNNExample, self).__init__()\n",
    "        self.conv = GCNConv(num_features, num_features)\n",
    "        self.batch_size = batch_size\n",
    "        self.input_dim = input_dim\n",
    "        self.num_features = num_features\n",
    "        self.num_samples = num_samples\n",
    "\n",
    "    def convolute(self, data):\n",
    "        xs = torch.tensor([])\n",
    "        for i in range(len(data)):\n",
    "            x, edge_index = data[i].x, data[i].edge_index\n",
    "            h = self.conv(x, edge_index)\n",
    "            h = h.sigmoid()\n",
    "            xs = torch.cat([xs, h])\n",
    "        return xs\n",
    "\n",
    "    def forward(self, data):\n",
    "        xs = self.convolute(data)\n",
    "        xs = torch.reshape(xs, (self.num_samples, self.input_dim))\n",
    "        return xs\n",
    "\n",
    "    def get_latent_space(self, data):\n",
    "        xs = self.convolute(data)\n",
    "        xs = torch.reshape(xs, (self.batch_size, self.input_dim))\n",
    "        return xs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c14c8a08-2d31-41e4-8d8c-8c301abd09d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Type\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "class MWE_AE(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, L):\n",
    "        super().__init__()\n",
    "\n",
    "        print(\"Initializing Minimal Working Example AE with input dim: \", input_dim)\n",
    "\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            custom_block(input_dim, 2500),\n",
    "            custom_block(2500, 2000),\n",
    "            custom_block(2000, 1500),\n",
    "            custom_block(1500, 1200),\n",
    "            custom_block(1200, 1000),\n",
    "            custom_block(1000, 800),\n",
    "            custom_block(800, 600),\n",
    "            custom_block(600, 400),\n",
    "            custom_block(400, 300),\n",
    "            custom_block(300, 150),\n",
    "            custom_block(150, 100),\n",
    "            custom_block(100, 50),\n",
    "            custom_block(50, L),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            custom_block(L, 50),\n",
    "            custom_block(50, 100),\n",
    "            custom_block(100, 150),\n",
    "            custom_block(150, 300),\n",
    "            custom_block(300, 400),\n",
    "            custom_block(400, 600),\n",
    "            custom_block(600, 800),\n",
    "            custom_block(800, 1000),\n",
    "            custom_block(1000, 1200),\n",
    "            custom_block(1200, 1500),\n",
    "            custom_block(1500, 2000),\n",
    "            custom_block(2000, 2500),\n",
    "            custom_block(2500, input_dim),\n",
    "            torch.nn.BatchNorm1d(input_dim),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "    def get_latent_space(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "\n",
    "def custom_block(input_dim, output_dim, dropout_rate=0.4):\n",
    "    return torch.nn.Sequential(\n",
    "        torch.nn.Linear(input_dim, output_dim),\n",
    "        torch.nn.BatchNorm1d(output_dim),\n",
    "        torch.nn.PReLU(),\n",
    "        torch.nn.Dropout(dropout_rate)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9e0c6b49-afa7-4286-8090-8f2ea447602c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset():\n",
    "    \"\"\"\n",
    "    This class is used to have all types of data in one place. For example, the entire train set can be housed\n",
    "    within this class. This way when we need to merge genData and cliData together, it can be done easily, as well\n",
    "    as checking the labels for later use.\n",
    "    \"\"\"\n",
    "    def __init__(self, genData, cliData, labels):\n",
    "        self.genData = genData\n",
    "        self.cliData = cliData\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.genData)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.genData[idx], self.cliData[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddeaa6d-76af-45d6-902d-af8260190b01",
   "metadata": {},
   "source": [
    "### TABULAR SIDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "d857fa1c-7066-4c4c-87d2-1882c1f3218f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NFKB1</th>\n",
       "      <th>TNIP2</th>\n",
       "      <th>AMOT</th>\n",
       "      <th>VASP</th>\n",
       "      <th>SS18L1</th>\n",
       "      <th>SMARCA4</th>\n",
       "      <th>SMURF1</th>\n",
       "      <th>HSPA5</th>\n",
       "      <th>SKIL</th>\n",
       "      <th>UBE2I</th>\n",
       "      <th>...</th>\n",
       "      <th>SULF2</th>\n",
       "      <th>CD276</th>\n",
       "      <th>TIPARP</th>\n",
       "      <th>PFS_P</th>\n",
       "      <th>PFS_P_CNSR</th>\n",
       "      <th>MATH</th>\n",
       "      <th>HE_TUMOR_CELL_CONTENT_IN_TUMOR_AREA</th>\n",
       "      <th>PD-L1_TOTAL_IMMUNE_CELLS_PER_TUMOR_AREA</th>\n",
       "      <th>CD8_POSITIVE_CELLS_TUMOR_CENTER</th>\n",
       "      <th>CD8_POSITIVE_CELLS_TOTAL_AREA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>X00936b9285d6b8665ae9122993fb8e91</th>\n",
       "      <td>6.10</td>\n",
       "      <td>4.38</td>\n",
       "      <td>3.07</td>\n",
       "      <td>6.14</td>\n",
       "      <td>4.70</td>\n",
       "      <td>7.52</td>\n",
       "      <td>4.93</td>\n",
       "      <td>8.37</td>\n",
       "      <td>6.21</td>\n",
       "      <td>5.69</td>\n",
       "      <td>...</td>\n",
       "      <td>8.68</td>\n",
       "      <td>7.09</td>\n",
       "      <td>4.94</td>\n",
       "      <td>4.172484</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.928391</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.1931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X105622fadc33f23755ac2df823110aca</th>\n",
       "      <td>5.07</td>\n",
       "      <td>3.33</td>\n",
       "      <td>1.73</td>\n",
       "      <td>5.11</td>\n",
       "      <td>5.62</td>\n",
       "      <td>6.58</td>\n",
       "      <td>4.34</td>\n",
       "      <td>7.42</td>\n",
       "      <td>6.15</td>\n",
       "      <td>4.86</td>\n",
       "      <td>...</td>\n",
       "      <td>6.08</td>\n",
       "      <td>6.56</td>\n",
       "      <td>4.61</td>\n",
       "      <td>16.591375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.122089</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.1214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xe44f39747a8e84b02b4cb24659312144</th>\n",
       "      <td>6.13</td>\n",
       "      <td>4.41</td>\n",
       "      <td>3.23</td>\n",
       "      <td>6.32</td>\n",
       "      <td>5.57</td>\n",
       "      <td>8.02</td>\n",
       "      <td>5.14</td>\n",
       "      <td>7.55</td>\n",
       "      <td>6.87</td>\n",
       "      <td>6.27</td>\n",
       "      <td>...</td>\n",
       "      <td>6.33</td>\n",
       "      <td>7.14</td>\n",
       "      <td>8.42</td>\n",
       "      <td>11.104723</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.616636</td>\n",
       "      <td>80.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.9203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X293dd1284496215e9a0eca9f17a98e7e</th>\n",
       "      <td>5.82</td>\n",
       "      <td>4.30</td>\n",
       "      <td>3.44</td>\n",
       "      <td>6.45</td>\n",
       "      <td>4.86</td>\n",
       "      <td>7.45</td>\n",
       "      <td>4.90</td>\n",
       "      <td>8.39</td>\n",
       "      <td>6.83</td>\n",
       "      <td>5.70</td>\n",
       "      <td>...</td>\n",
       "      <td>6.97</td>\n",
       "      <td>6.73</td>\n",
       "      <td>6.28</td>\n",
       "      <td>14.028748</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.817434</td>\n",
       "      <td>60.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.16</td>\n",
       "      <td>3.1635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X01ed7190ce00862696edbf047b542045</th>\n",
       "      <td>6.15</td>\n",
       "      <td>4.21</td>\n",
       "      <td>3.90</td>\n",
       "      <td>5.93</td>\n",
       "      <td>4.43</td>\n",
       "      <td>7.60</td>\n",
       "      <td>4.74</td>\n",
       "      <td>8.31</td>\n",
       "      <td>6.38</td>\n",
       "      <td>5.94</td>\n",
       "      <td>...</td>\n",
       "      <td>5.67</td>\n",
       "      <td>6.66</td>\n",
       "      <td>4.93</td>\n",
       "      <td>12.418891</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.303864</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.98</td>\n",
       "      <td>2.0708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xc3d410d70dd7359baa40126494fb6765</th>\n",
       "      <td>6.25</td>\n",
       "      <td>3.62</td>\n",
       "      <td>4.80</td>\n",
       "      <td>4.72</td>\n",
       "      <td>5.39</td>\n",
       "      <td>7.01</td>\n",
       "      <td>4.57</td>\n",
       "      <td>6.96</td>\n",
       "      <td>6.26</td>\n",
       "      <td>5.70</td>\n",
       "      <td>...</td>\n",
       "      <td>2.40</td>\n",
       "      <td>6.58</td>\n",
       "      <td>6.59</td>\n",
       "      <td>9.790554</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.552612</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.0089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X50772aa64efb859960b20f8801cd6f58</th>\n",
       "      <td>6.27</td>\n",
       "      <td>3.78</td>\n",
       "      <td>3.98</td>\n",
       "      <td>5.95</td>\n",
       "      <td>4.66</td>\n",
       "      <td>7.18</td>\n",
       "      <td>4.61</td>\n",
       "      <td>8.04</td>\n",
       "      <td>6.62</td>\n",
       "      <td>5.80</td>\n",
       "      <td>...</td>\n",
       "      <td>5.92</td>\n",
       "      <td>6.74</td>\n",
       "      <td>5.48</td>\n",
       "      <td>4.271047</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.672304</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.1775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X91bcd3067a1a7954692d836515e04869</th>\n",
       "      <td>6.12</td>\n",
       "      <td>3.94</td>\n",
       "      <td>3.25</td>\n",
       "      <td>6.09</td>\n",
       "      <td>4.98</td>\n",
       "      <td>7.32</td>\n",
       "      <td>5.02</td>\n",
       "      <td>8.21</td>\n",
       "      <td>6.71</td>\n",
       "      <td>5.89</td>\n",
       "      <td>...</td>\n",
       "      <td>7.84</td>\n",
       "      <td>7.59</td>\n",
       "      <td>7.59</td>\n",
       "      <td>2.496920</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.837849</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.03</td>\n",
       "      <td>3.9642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xc7439a06ffa32b313b0ec1b987b992a2</th>\n",
       "      <td>5.91</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.34</td>\n",
       "      <td>5.80</td>\n",
       "      <td>8.86</td>\n",
       "      <td>8.69</td>\n",
       "      <td>4.52</td>\n",
       "      <td>8.15</td>\n",
       "      <td>5.77</td>\n",
       "      <td>6.85</td>\n",
       "      <td>...</td>\n",
       "      <td>6.81</td>\n",
       "      <td>6.82</td>\n",
       "      <td>5.27</td>\n",
       "      <td>6.505134</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.606825</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.1417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X21a6043653d187f8bbead475d2f49791</th>\n",
       "      <td>6.48</td>\n",
       "      <td>4.32</td>\n",
       "      <td>2.27</td>\n",
       "      <td>6.10</td>\n",
       "      <td>5.13</td>\n",
       "      <td>7.83</td>\n",
       "      <td>5.18</td>\n",
       "      <td>8.34</td>\n",
       "      <td>6.70</td>\n",
       "      <td>6.02</td>\n",
       "      <td>...</td>\n",
       "      <td>6.70</td>\n",
       "      <td>7.98</td>\n",
       "      <td>5.24</td>\n",
       "      <td>5.683778</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.627516</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.1024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>650 rows × 2873 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   NFKB1  TNIP2  AMOT  VASP  SS18L1  SMARCA4  \\\n",
       "id                                                                             \n",
       "X00936b9285d6b8665ae9122993fb8e91   6.10   4.38  3.07  6.14    4.70     7.52   \n",
       "X105622fadc33f23755ac2df823110aca   5.07   3.33  1.73  5.11    5.62     6.58   \n",
       "Xe44f39747a8e84b02b4cb24659312144   6.13   4.41  3.23  6.32    5.57     8.02   \n",
       "X293dd1284496215e9a0eca9f17a98e7e   5.82   4.30  3.44  6.45    4.86     7.45   \n",
       "X01ed7190ce00862696edbf047b542045   6.15   4.21  3.90  5.93    4.43     7.60   \n",
       "...                                  ...    ...   ...   ...     ...      ...   \n",
       "Xc3d410d70dd7359baa40126494fb6765   6.25   3.62  4.80  4.72    5.39     7.01   \n",
       "X50772aa64efb859960b20f8801cd6f58   6.27   3.78  3.98  5.95    4.66     7.18   \n",
       "X91bcd3067a1a7954692d836515e04869   6.12   3.94  3.25  6.09    4.98     7.32   \n",
       "Xc7439a06ffa32b313b0ec1b987b992a2   5.91   3.62  3.34  5.80    8.86     8.69   \n",
       "X21a6043653d187f8bbead475d2f49791   6.48   4.32  2.27  6.10    5.13     7.83   \n",
       "\n",
       "                                   SMURF1  HSPA5  SKIL  UBE2I  ...  SULF2  \\\n",
       "id                                                             ...          \n",
       "X00936b9285d6b8665ae9122993fb8e91    4.93   8.37  6.21   5.69  ...   8.68   \n",
       "X105622fadc33f23755ac2df823110aca    4.34   7.42  6.15   4.86  ...   6.08   \n",
       "Xe44f39747a8e84b02b4cb24659312144    5.14   7.55  6.87   6.27  ...   6.33   \n",
       "X293dd1284496215e9a0eca9f17a98e7e    4.90   8.39  6.83   5.70  ...   6.97   \n",
       "X01ed7190ce00862696edbf047b542045    4.74   8.31  6.38   5.94  ...   5.67   \n",
       "...                                   ...    ...   ...    ...  ...    ...   \n",
       "Xc3d410d70dd7359baa40126494fb6765    4.57   6.96  6.26   5.70  ...   2.40   \n",
       "X50772aa64efb859960b20f8801cd6f58    4.61   8.04  6.62   5.80  ...   5.92   \n",
       "X91bcd3067a1a7954692d836515e04869    5.02   8.21  6.71   5.89  ...   7.84   \n",
       "Xc7439a06ffa32b313b0ec1b987b992a2    4.52   8.15  5.77   6.85  ...   6.81   \n",
       "X21a6043653d187f8bbead475d2f49791    5.18   8.34  6.70   6.02  ...   6.70   \n",
       "\n",
       "                                   CD276  TIPARP      PFS_P  PFS_P_CNSR  \\\n",
       "id                                                                        \n",
       "X00936b9285d6b8665ae9122993fb8e91   7.09    4.94   4.172484         0.0   \n",
       "X105622fadc33f23755ac2df823110aca   6.56    4.61  16.591375         1.0   \n",
       "Xe44f39747a8e84b02b4cb24659312144   7.14    8.42  11.104723         0.0   \n",
       "X293dd1284496215e9a0eca9f17a98e7e   6.73    6.28  14.028748         1.0   \n",
       "X01ed7190ce00862696edbf047b542045   6.66    4.93  12.418891         0.0   \n",
       "...                                  ...     ...        ...         ...   \n",
       "Xc3d410d70dd7359baa40126494fb6765   6.58    6.59   9.790554         1.0   \n",
       "X50772aa64efb859960b20f8801cd6f58   6.74    5.48   4.271047         0.0   \n",
       "X91bcd3067a1a7954692d836515e04869   7.59    7.59   2.496920         0.0   \n",
       "Xc7439a06ffa32b313b0ec1b987b992a2   6.82    5.27   6.505134         1.0   \n",
       "X21a6043653d187f8bbead475d2f49791   7.98    5.24   5.683778         1.0   \n",
       "\n",
       "                                        MATH  \\\n",
       "id                                             \n",
       "X00936b9285d6b8665ae9122993fb8e91  17.928391   \n",
       "X105622fadc33f23755ac2df823110aca  16.122089   \n",
       "Xe44f39747a8e84b02b4cb24659312144  23.616636   \n",
       "X293dd1284496215e9a0eca9f17a98e7e  24.817434   \n",
       "X01ed7190ce00862696edbf047b542045  19.303864   \n",
       "...                                      ...   \n",
       "Xc3d410d70dd7359baa40126494fb6765  24.552612   \n",
       "X50772aa64efb859960b20f8801cd6f58  15.672304   \n",
       "X91bcd3067a1a7954692d836515e04869  27.837849   \n",
       "Xc7439a06ffa32b313b0ec1b987b992a2  26.606825   \n",
       "X21a6043653d187f8bbead475d2f49791  17.627516   \n",
       "\n",
       "                                   HE_TUMOR_CELL_CONTENT_IN_TUMOR_AREA  \\\n",
       "id                                                                       \n",
       "X00936b9285d6b8665ae9122993fb8e91                                 70.0   \n",
       "X105622fadc33f23755ac2df823110aca                                 85.0   \n",
       "Xe44f39747a8e84b02b4cb24659312144                                 80.0   \n",
       "X293dd1284496215e9a0eca9f17a98e7e                                 60.0   \n",
       "X01ed7190ce00862696edbf047b542045                                 80.0   \n",
       "...                                                                ...   \n",
       "Xc3d410d70dd7359baa40126494fb6765                                 75.0   \n",
       "X50772aa64efb859960b20f8801cd6f58                                 75.0   \n",
       "X91bcd3067a1a7954692d836515e04869                                 50.0   \n",
       "Xc7439a06ffa32b313b0ec1b987b992a2                                 80.0   \n",
       "X21a6043653d187f8bbead475d2f49791                                 70.0   \n",
       "\n",
       "                                   PD-L1_TOTAL_IMMUNE_CELLS_PER_TUMOR_AREA  \\\n",
       "id                                                                           \n",
       "X00936b9285d6b8665ae9122993fb8e91                                      0.0   \n",
       "X105622fadc33f23755ac2df823110aca                                      1.0   \n",
       "Xe44f39747a8e84b02b4cb24659312144                                      5.0   \n",
       "X293dd1284496215e9a0eca9f17a98e7e                                      5.0   \n",
       "X01ed7190ce00862696edbf047b542045                                      2.0   \n",
       "...                                                                    ...   \n",
       "Xc3d410d70dd7359baa40126494fb6765                                      0.0   \n",
       "X50772aa64efb859960b20f8801cd6f58                                      1.0   \n",
       "X91bcd3067a1a7954692d836515e04869                                      1.0   \n",
       "Xc7439a06ffa32b313b0ec1b987b992a2                                      1.0   \n",
       "X21a6043653d187f8bbead475d2f49791                                      0.0   \n",
       "\n",
       "                                   CD8_POSITIVE_CELLS_TUMOR_CENTER  \\\n",
       "id                                                                   \n",
       "X00936b9285d6b8665ae9122993fb8e91                             0.08   \n",
       "X105622fadc33f23755ac2df823110aca                             0.12   \n",
       "Xe44f39747a8e84b02b4cb24659312144                             0.92   \n",
       "X293dd1284496215e9a0eca9f17a98e7e                             3.16   \n",
       "X01ed7190ce00862696edbf047b542045                             1.98   \n",
       "...                                                            ...   \n",
       "Xc3d410d70dd7359baa40126494fb6765                             1.01   \n",
       "X50772aa64efb859960b20f8801cd6f58                             1.10   \n",
       "X91bcd3067a1a7954692d836515e04869                             4.03   \n",
       "Xc7439a06ffa32b313b0ec1b987b992a2                             0.14   \n",
       "X21a6043653d187f8bbead475d2f49791                             3.10   \n",
       "\n",
       "                                   CD8_POSITIVE_CELLS_TOTAL_AREA  \n",
       "id                                                                \n",
       "X00936b9285d6b8665ae9122993fb8e91                         0.1931  \n",
       "X105622fadc33f23755ac2df823110aca                         0.1214  \n",
       "Xe44f39747a8e84b02b4cb24659312144                         0.9203  \n",
       "X293dd1284496215e9a0eca9f17a98e7e                         3.1635  \n",
       "X01ed7190ce00862696edbf047b542045                         2.0708  \n",
       "...                                                          ...  \n",
       "Xc3d410d70dd7359baa40126494fb6765                         1.0089  \n",
       "X50772aa64efb859960b20f8801cd6f58                         1.1775  \n",
       "X91bcd3067a1a7954692d836515e04869                         3.9642  \n",
       "Xc7439a06ffa32b313b0ec1b987b992a2                         0.1417  \n",
       "X21a6043653d187f8bbead475d2f49791                         3.1024  \n",
       "\n",
       "[650 rows x 2873 columns]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_directory = os.getcwd()\n",
    "\n",
    "somepath = os.path.abspath(\n",
    "    os.path.join(current_directory, '..', 'Data', 'RNA_dataset_tabular_R3.csv'))\n",
    "\n",
    "# expression data\n",
    "tabular_data = pd.read_csv(somepath, sep = ',', index_col = 0)\n",
    "tabular_data = tabular_data.astype('float32')\n",
    "gene_data = tabular_data\n",
    "gene_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "89eeeecb-ed7d-4b37-b588-b9359a06f7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cli_vars = ['PFS_P', 'PFS_P_CNSR', 'MATH', 'HE_TUMOR_CELL_CONTENT_IN_TUMOR_AREA', 'PD-L1_TOTAL_IMMUNE_CELLS_PER_TUMOR_AREA', 'CD8_POSITIVE_CELLS_TUMOR_CENTER', 'CD8_POSITIVE_CELLS_TOTAL_AREA']\n",
    "gene_data = tabular_data.drop(columns = cli_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "224606a8-1923-444b-846e-6c25fe97f54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxVal = max([x for L in gene_data.values for x in L])\n",
    "X_normalized = gene_data / maxVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "e700c95f-68c2-4f4f-b0d6-44312ccf723f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NFKB1</th>\n",
       "      <th>TNIP2</th>\n",
       "      <th>AMOT</th>\n",
       "      <th>VASP</th>\n",
       "      <th>SS18L1</th>\n",
       "      <th>SMARCA4</th>\n",
       "      <th>SMURF1</th>\n",
       "      <th>HSPA5</th>\n",
       "      <th>SKIL</th>\n",
       "      <th>UBE2I</th>\n",
       "      <th>...</th>\n",
       "      <th>SLC22A3</th>\n",
       "      <th>SPAG16</th>\n",
       "      <th>HTATIP2</th>\n",
       "      <th>SLC17A1</th>\n",
       "      <th>MGST2</th>\n",
       "      <th>CHPT1</th>\n",
       "      <th>STK17A</th>\n",
       "      <th>SULF2</th>\n",
       "      <th>CD276</th>\n",
       "      <th>TIPARP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>X00936b9285d6b8665ae9122993fb8e91</th>\n",
       "      <td>0.395078</td>\n",
       "      <td>0.283679</td>\n",
       "      <td>0.198834</td>\n",
       "      <td>0.397668</td>\n",
       "      <td>0.304404</td>\n",
       "      <td>0.487047</td>\n",
       "      <td>0.319301</td>\n",
       "      <td>0.542098</td>\n",
       "      <td>0.402202</td>\n",
       "      <td>0.368523</td>\n",
       "      <td>...</td>\n",
       "      <td>0.163860</td>\n",
       "      <td>0.281736</td>\n",
       "      <td>0.288212</td>\n",
       "      <td>0.289508</td>\n",
       "      <td>0.457902</td>\n",
       "      <td>0.338731</td>\n",
       "      <td>0.264249</td>\n",
       "      <td>0.562176</td>\n",
       "      <td>0.459197</td>\n",
       "      <td>0.319948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X105622fadc33f23755ac2df823110aca</th>\n",
       "      <td>0.328368</td>\n",
       "      <td>0.215674</td>\n",
       "      <td>0.112047</td>\n",
       "      <td>0.330959</td>\n",
       "      <td>0.363990</td>\n",
       "      <td>0.426166</td>\n",
       "      <td>0.281088</td>\n",
       "      <td>0.480570</td>\n",
       "      <td>0.398316</td>\n",
       "      <td>0.314767</td>\n",
       "      <td>...</td>\n",
       "      <td>0.371762</td>\n",
       "      <td>0.287565</td>\n",
       "      <td>0.308290</td>\n",
       "      <td>0.288212</td>\n",
       "      <td>0.479275</td>\n",
       "      <td>0.443005</td>\n",
       "      <td>0.183938</td>\n",
       "      <td>0.393782</td>\n",
       "      <td>0.424870</td>\n",
       "      <td>0.298575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xe44f39747a8e84b02b4cb24659312144</th>\n",
       "      <td>0.397021</td>\n",
       "      <td>0.285622</td>\n",
       "      <td>0.209197</td>\n",
       "      <td>0.409326</td>\n",
       "      <td>0.360751</td>\n",
       "      <td>0.519430</td>\n",
       "      <td>0.332902</td>\n",
       "      <td>0.488990</td>\n",
       "      <td>0.444948</td>\n",
       "      <td>0.406088</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300518</td>\n",
       "      <td>0.264249</td>\n",
       "      <td>0.299870</td>\n",
       "      <td>0.190415</td>\n",
       "      <td>0.431347</td>\n",
       "      <td>0.376295</td>\n",
       "      <td>0.269430</td>\n",
       "      <td>0.409974</td>\n",
       "      <td>0.462435</td>\n",
       "      <td>0.545337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X293dd1284496215e9a0eca9f17a98e7e</th>\n",
       "      <td>0.376943</td>\n",
       "      <td>0.278497</td>\n",
       "      <td>0.222798</td>\n",
       "      <td>0.417746</td>\n",
       "      <td>0.314767</td>\n",
       "      <td>0.482513</td>\n",
       "      <td>0.317358</td>\n",
       "      <td>0.543394</td>\n",
       "      <td>0.442358</td>\n",
       "      <td>0.369171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.292746</td>\n",
       "      <td>0.306995</td>\n",
       "      <td>0.318653</td>\n",
       "      <td>0.053756</td>\n",
       "      <td>0.431995</td>\n",
       "      <td>0.341321</td>\n",
       "      <td>0.266839</td>\n",
       "      <td>0.451425</td>\n",
       "      <td>0.435881</td>\n",
       "      <td>0.406736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X01ed7190ce00862696edbf047b542045</th>\n",
       "      <td>0.398316</td>\n",
       "      <td>0.272668</td>\n",
       "      <td>0.252591</td>\n",
       "      <td>0.384067</td>\n",
       "      <td>0.286917</td>\n",
       "      <td>0.492228</td>\n",
       "      <td>0.306995</td>\n",
       "      <td>0.538212</td>\n",
       "      <td>0.413212</td>\n",
       "      <td>0.384715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127591</td>\n",
       "      <td>0.347798</td>\n",
       "      <td>0.361399</td>\n",
       "      <td>0.433938</td>\n",
       "      <td>0.422927</td>\n",
       "      <td>0.378238</td>\n",
       "      <td>0.281736</td>\n",
       "      <td>0.367228</td>\n",
       "      <td>0.431347</td>\n",
       "      <td>0.319301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xc3d410d70dd7359baa40126494fb6765</th>\n",
       "      <td>0.404793</td>\n",
       "      <td>0.234456</td>\n",
       "      <td>0.310881</td>\n",
       "      <td>0.305699</td>\n",
       "      <td>0.349093</td>\n",
       "      <td>0.454016</td>\n",
       "      <td>0.295984</td>\n",
       "      <td>0.450777</td>\n",
       "      <td>0.405440</td>\n",
       "      <td>0.369171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.370466</td>\n",
       "      <td>0.457902</td>\n",
       "      <td>0.306995</td>\n",
       "      <td>0.448187</td>\n",
       "      <td>0.367228</td>\n",
       "      <td>0.488990</td>\n",
       "      <td>0.150259</td>\n",
       "      <td>0.155440</td>\n",
       "      <td>0.426166</td>\n",
       "      <td>0.426813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X50772aa64efb859960b20f8801cd6f58</th>\n",
       "      <td>0.406088</td>\n",
       "      <td>0.244819</td>\n",
       "      <td>0.257772</td>\n",
       "      <td>0.385363</td>\n",
       "      <td>0.301813</td>\n",
       "      <td>0.465026</td>\n",
       "      <td>0.298575</td>\n",
       "      <td>0.520725</td>\n",
       "      <td>0.428756</td>\n",
       "      <td>0.375648</td>\n",
       "      <td>...</td>\n",
       "      <td>0.312824</td>\n",
       "      <td>0.372409</td>\n",
       "      <td>0.360751</td>\n",
       "      <td>0.505829</td>\n",
       "      <td>0.470207</td>\n",
       "      <td>0.398316</td>\n",
       "      <td>0.227979</td>\n",
       "      <td>0.383420</td>\n",
       "      <td>0.436529</td>\n",
       "      <td>0.354922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X91bcd3067a1a7954692d836515e04869</th>\n",
       "      <td>0.396373</td>\n",
       "      <td>0.255181</td>\n",
       "      <td>0.210492</td>\n",
       "      <td>0.394430</td>\n",
       "      <td>0.322539</td>\n",
       "      <td>0.474093</td>\n",
       "      <td>0.325130</td>\n",
       "      <td>0.531736</td>\n",
       "      <td>0.434586</td>\n",
       "      <td>0.381477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199482</td>\n",
       "      <td>0.313472</td>\n",
       "      <td>0.338731</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>0.413212</td>\n",
       "      <td>0.336788</td>\n",
       "      <td>0.262306</td>\n",
       "      <td>0.507772</td>\n",
       "      <td>0.491580</td>\n",
       "      <td>0.491580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xc7439a06ffa32b313b0ec1b987b992a2</th>\n",
       "      <td>0.382772</td>\n",
       "      <td>0.234456</td>\n",
       "      <td>0.216321</td>\n",
       "      <td>0.375648</td>\n",
       "      <td>0.573834</td>\n",
       "      <td>0.562824</td>\n",
       "      <td>0.292746</td>\n",
       "      <td>0.527850</td>\n",
       "      <td>0.373705</td>\n",
       "      <td>0.443653</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060881</td>\n",
       "      <td>0.389896</td>\n",
       "      <td>0.261658</td>\n",
       "      <td>0.473446</td>\n",
       "      <td>0.437824</td>\n",
       "      <td>0.461140</td>\n",
       "      <td>0.210492</td>\n",
       "      <td>0.441062</td>\n",
       "      <td>0.441710</td>\n",
       "      <td>0.341321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X21a6043653d187f8bbead475d2f49791</th>\n",
       "      <td>0.419689</td>\n",
       "      <td>0.279793</td>\n",
       "      <td>0.147021</td>\n",
       "      <td>0.395078</td>\n",
       "      <td>0.332254</td>\n",
       "      <td>0.507124</td>\n",
       "      <td>0.335492</td>\n",
       "      <td>0.540155</td>\n",
       "      <td>0.433938</td>\n",
       "      <td>0.389896</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055699</td>\n",
       "      <td>0.417746</td>\n",
       "      <td>0.360104</td>\n",
       "      <td>0.593912</td>\n",
       "      <td>0.455959</td>\n",
       "      <td>0.353627</td>\n",
       "      <td>0.265544</td>\n",
       "      <td>0.433938</td>\n",
       "      <td>0.516839</td>\n",
       "      <td>0.339378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>650 rows × 2866 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      NFKB1     TNIP2      AMOT      VASP  \\\n",
       "id                                                                          \n",
       "X00936b9285d6b8665ae9122993fb8e91  0.395078  0.283679  0.198834  0.397668   \n",
       "X105622fadc33f23755ac2df823110aca  0.328368  0.215674  0.112047  0.330959   \n",
       "Xe44f39747a8e84b02b4cb24659312144  0.397021  0.285622  0.209197  0.409326   \n",
       "X293dd1284496215e9a0eca9f17a98e7e  0.376943  0.278497  0.222798  0.417746   \n",
       "X01ed7190ce00862696edbf047b542045  0.398316  0.272668  0.252591  0.384067   \n",
       "...                                     ...       ...       ...       ...   \n",
       "Xc3d410d70dd7359baa40126494fb6765  0.404793  0.234456  0.310881  0.305699   \n",
       "X50772aa64efb859960b20f8801cd6f58  0.406088  0.244819  0.257772  0.385363   \n",
       "X91bcd3067a1a7954692d836515e04869  0.396373  0.255181  0.210492  0.394430   \n",
       "Xc7439a06ffa32b313b0ec1b987b992a2  0.382772  0.234456  0.216321  0.375648   \n",
       "X21a6043653d187f8bbead475d2f49791  0.419689  0.279793  0.147021  0.395078   \n",
       "\n",
       "                                     SS18L1   SMARCA4    SMURF1     HSPA5  \\\n",
       "id                                                                          \n",
       "X00936b9285d6b8665ae9122993fb8e91  0.304404  0.487047  0.319301  0.542098   \n",
       "X105622fadc33f23755ac2df823110aca  0.363990  0.426166  0.281088  0.480570   \n",
       "Xe44f39747a8e84b02b4cb24659312144  0.360751  0.519430  0.332902  0.488990   \n",
       "X293dd1284496215e9a0eca9f17a98e7e  0.314767  0.482513  0.317358  0.543394   \n",
       "X01ed7190ce00862696edbf047b542045  0.286917  0.492228  0.306995  0.538212   \n",
       "...                                     ...       ...       ...       ...   \n",
       "Xc3d410d70dd7359baa40126494fb6765  0.349093  0.454016  0.295984  0.450777   \n",
       "X50772aa64efb859960b20f8801cd6f58  0.301813  0.465026  0.298575  0.520725   \n",
       "X91bcd3067a1a7954692d836515e04869  0.322539  0.474093  0.325130  0.531736   \n",
       "Xc7439a06ffa32b313b0ec1b987b992a2  0.573834  0.562824  0.292746  0.527850   \n",
       "X21a6043653d187f8bbead475d2f49791  0.332254  0.507124  0.335492  0.540155   \n",
       "\n",
       "                                       SKIL     UBE2I  ...   SLC22A3  \\\n",
       "id                                                     ...             \n",
       "X00936b9285d6b8665ae9122993fb8e91  0.402202  0.368523  ...  0.163860   \n",
       "X105622fadc33f23755ac2df823110aca  0.398316  0.314767  ...  0.371762   \n",
       "Xe44f39747a8e84b02b4cb24659312144  0.444948  0.406088  ...  0.300518   \n",
       "X293dd1284496215e9a0eca9f17a98e7e  0.442358  0.369171  ...  0.292746   \n",
       "X01ed7190ce00862696edbf047b542045  0.413212  0.384715  ...  0.127591   \n",
       "...                                     ...       ...  ...       ...   \n",
       "Xc3d410d70dd7359baa40126494fb6765  0.405440  0.369171  ...  0.370466   \n",
       "X50772aa64efb859960b20f8801cd6f58  0.428756  0.375648  ...  0.312824   \n",
       "X91bcd3067a1a7954692d836515e04869  0.434586  0.381477  ...  0.199482   \n",
       "Xc7439a06ffa32b313b0ec1b987b992a2  0.373705  0.443653  ...  0.060881   \n",
       "X21a6043653d187f8bbead475d2f49791  0.433938  0.389896  ...  0.055699   \n",
       "\n",
       "                                     SPAG16   HTATIP2   SLC17A1     MGST2  \\\n",
       "id                                                                          \n",
       "X00936b9285d6b8665ae9122993fb8e91  0.281736  0.288212  0.289508  0.457902   \n",
       "X105622fadc33f23755ac2df823110aca  0.287565  0.308290  0.288212  0.479275   \n",
       "Xe44f39747a8e84b02b4cb24659312144  0.264249  0.299870  0.190415  0.431347   \n",
       "X293dd1284496215e9a0eca9f17a98e7e  0.306995  0.318653  0.053756  0.431995   \n",
       "X01ed7190ce00862696edbf047b542045  0.347798  0.361399  0.433938  0.422927   \n",
       "...                                     ...       ...       ...       ...   \n",
       "Xc3d410d70dd7359baa40126494fb6765  0.457902  0.306995  0.448187  0.367228   \n",
       "X50772aa64efb859960b20f8801cd6f58  0.372409  0.360751  0.505829  0.470207   \n",
       "X91bcd3067a1a7954692d836515e04869  0.313472  0.338731  0.000648  0.413212   \n",
       "Xc7439a06ffa32b313b0ec1b987b992a2  0.389896  0.261658  0.473446  0.437824   \n",
       "X21a6043653d187f8bbead475d2f49791  0.417746  0.360104  0.593912  0.455959   \n",
       "\n",
       "                                      CHPT1    STK17A     SULF2     CD276  \\\n",
       "id                                                                          \n",
       "X00936b9285d6b8665ae9122993fb8e91  0.338731  0.264249  0.562176  0.459197   \n",
       "X105622fadc33f23755ac2df823110aca  0.443005  0.183938  0.393782  0.424870   \n",
       "Xe44f39747a8e84b02b4cb24659312144  0.376295  0.269430  0.409974  0.462435   \n",
       "X293dd1284496215e9a0eca9f17a98e7e  0.341321  0.266839  0.451425  0.435881   \n",
       "X01ed7190ce00862696edbf047b542045  0.378238  0.281736  0.367228  0.431347   \n",
       "...                                     ...       ...       ...       ...   \n",
       "Xc3d410d70dd7359baa40126494fb6765  0.488990  0.150259  0.155440  0.426166   \n",
       "X50772aa64efb859960b20f8801cd6f58  0.398316  0.227979  0.383420  0.436529   \n",
       "X91bcd3067a1a7954692d836515e04869  0.336788  0.262306  0.507772  0.491580   \n",
       "Xc7439a06ffa32b313b0ec1b987b992a2  0.461140  0.210492  0.441062  0.441710   \n",
       "X21a6043653d187f8bbead475d2f49791  0.353627  0.265544  0.433938  0.516839   \n",
       "\n",
       "                                     TIPARP  \n",
       "id                                           \n",
       "X00936b9285d6b8665ae9122993fb8e91  0.319948  \n",
       "X105622fadc33f23755ac2df823110aca  0.298575  \n",
       "Xe44f39747a8e84b02b4cb24659312144  0.545337  \n",
       "X293dd1284496215e9a0eca9f17a98e7e  0.406736  \n",
       "X01ed7190ce00862696edbf047b542045  0.319301  \n",
       "...                                     ...  \n",
       "Xc3d410d70dd7359baa40126494fb6765  0.426813  \n",
       "X50772aa64efb859960b20f8801cd6f58  0.354922  \n",
       "X91bcd3067a1a7954692d836515e04869  0.491580  \n",
       "Xc7439a06ffa32b313b0ec1b987b992a2  0.341321  \n",
       "X21a6043653d187f8bbead475d2f49791  0.339378  \n",
       "\n",
       "[650 rows x 2866 columns]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "ea96e5f7-87db-4260-b726-71225de3306f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "torch_tensor = torch.tensor(X_normalized.values)\n",
    "\n",
    "data = CustomDataset(torch_tensor, [1] * len(torch_tensor), [2] * len(torch_tensor))\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = list(DataLoader(data, batch_size=batch_size, shuffle=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "01d3c0a8-60bf-4a57-8c87-3b410045eda1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2.])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = list(train_loader)\n",
    "res = torch.tensor([])\n",
    "for x in X:\n",
    "    res = torch.cat((res, x[2]), dim=0)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ab80194c-35d4-4143-8b57-69e99da559f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Minimal Working Example AE with input dim:  2866\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.4127, 0.3174, 0.9258,  ..., 0.3901, 0.5520, 0.3169],\n",
       "        [0.4575, 0.3279, 0.6706,  ..., 0.9447, 0.7058, 0.4176],\n",
       "        [0.4127, 0.3884, 0.6172,  ..., 0.2966, 0.3303, 0.4176],\n",
       "        ...,\n",
       "        [0.3089, 0.4147, 0.4174,  ..., 0.7215, 0.4200, 0.9184],\n",
       "        [0.4127, 0.4273, 0.4162,  ..., 0.7860, 0.4790, 0.3998],\n",
       "        [0.7091, 0.5397, 0.3998,  ..., 0.4216, 0.2475, 0.4176]],\n",
       "       grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tab = MWE_AE(2866, 50)\n",
    "lat = model_tab(res)\n",
    "lat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278d236d-e445-47dc-add9-df8872978673",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fda5e2a-e444-437b-9a62-9486ad3e8ffb",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13379fe5-383d-4276-b5a9-e6ebd5b5565a",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf18b95-03d0-40ae-9e45-88cdb712890d",
   "metadata": {},
   "source": [
    "### GRAPH SIDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3ab1a719-b8a9-43fd-a502-8bc9be0c172a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "somepath = os.path.abspath(\n",
    "    os.path.join(current_directory, '..', 'Data', 'RNA_dataset_graph_R3.pkl'))\n",
    "\n",
    "with open(somepath, 'rb') as f:\n",
    "    loaded_object = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1ed4b184-99fe-4b10-bc73-1da398dbeafd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.1000, 4.3800, 3.0700,  ..., 8.6800, 7.0900, 4.9400],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = loaded_object[0]\n",
    "features = []\n",
    "for node, attr in G.nodes(data = True):\n",
    "    features += [attr['node_attr']]\n",
    "features = torch.tensor(features)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "8cec6e04-76c3-4eb0-92f5-12a9a9abc684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2866], edge_index=[2, 90932])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "data = None\n",
    "\n",
    "G = loaded_object[0]\n",
    "# we enumerate each node in a dict\n",
    "node_to_index = {node: idx for idx, node in enumerate(G.nodes())}\n",
    "\n",
    "edge_index = torch.tensor([(node_to_index[edge[0]], node_to_index[edge[1]]) for edge in G.edges()] +\n",
    "                 [(node_to_index[edge[1]], node_to_index[edge[0]]) for edge in G.edges()]).t().contiguous()\n",
    "data = Data(x= features, edge_index = edge_index)\n",
    "data.validate(raise_on_error=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "dbed410c-7db2-4e76-814f-73e6e48a7327",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_all_graph_data(graphs):\n",
    "    D = []\n",
    "    # edges are the same for all graphs so we only need to compute this once.\n",
    "    G = graphs[0]\n",
    "    node_to_index = {node: idx for idx, node in enumerate(G.nodes())}\n",
    "\n",
    "    edge_index = torch.tensor([(node_to_index[edge[0]], node_to_index[edge[1]]) for edge in G.edges()] +\n",
    "                 [(node_to_index[edge[1]], node_to_index[edge[0]]) for edge in G.edges()]).t().contiguous()\n",
    "    \n",
    "    for g in graphs:\n",
    "        features = []\n",
    "        for node, attr in g.nodes(data = True):\n",
    "            features += [[float(attr['node_attr'])]]\n",
    "        features = torch.tensor(features)\n",
    "        d = Data(x = features, edge_index = edge_index)\n",
    "        d.validate(raise_on_error=True)\n",
    "        D += [d]\n",
    "    return D\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7217b988-82c7-428b-87af-ddf5f714de06",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = collect_all_graph_data(loaded_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "35ca7e1f-56a7-4de9-9588-c7aea65c8244",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[DataBatch(x=[183424, 1], edge_index=[2, 5819648], batch=[183424], ptr=[65]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])],\n",
       " [DataBatch(x=[183424, 1], edge_index=[2, 5819648], batch=[183424], ptr=[65]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])],\n",
       " [DataBatch(x=[183424, 1], edge_index=[2, 5819648], batch=[183424], ptr=[65]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])],\n",
       " [DataBatch(x=[183424, 1], edge_index=[2, 5819648], batch=[183424], ptr=[65]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])],\n",
       " [DataBatch(x=[183424, 1], edge_index=[2, 5819648], batch=[183424], ptr=[65]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])],\n",
       " [DataBatch(x=[183424, 1], edge_index=[2, 5819648], batch=[183424], ptr=[65]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])],\n",
       " [DataBatch(x=[183424, 1], edge_index=[2, 5819648], batch=[183424], ptr=[65]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])],\n",
       " [DataBatch(x=[183424, 1], edge_index=[2, 5819648], batch=[183424], ptr=[65]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])],\n",
       " [DataBatch(x=[183424, 1], edge_index=[2, 5819648], batch=[183424], ptr=[65]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])],\n",
       " [DataBatch(x=[183424, 1], edge_index=[2, 5819648], batch=[183424], ptr=[65]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])],\n",
       " [DataBatch(x=[28660, 1], edge_index=[2, 909320], batch=[28660], ptr=[11]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2])]]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "custom_dataset = CustomDataset(X, [1] * len(X), [2] * len(X))\n",
    "    \n",
    "loader = list(DataLoader(custom_dataset, batch_size=64, shuffle=False))\n",
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "c3300c24-e3fc-497d-b892-e556cba68660",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(loader)\n",
    "dim = 0\n",
    "res = []\n",
    "for x in X:\n",
    "    res += [x[dim]]\n",
    "z = list(DataLoader(res, batch_size = len(res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "fd818d63-c4dc-484f-b46d-2a38aaa70820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[1862900, 1], edge_index=[2, 59105800], batch=[1862900])"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "0db0849f-5627-4868-9f38-f840ad5d3b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9231, 0.7012, 0.8368,  ..., 0.7934, 0.7635, 0.6901],\n",
       "        [0.9042, 0.6851, 0.8098,  ..., 0.7188, 0.7471, 0.6788],\n",
       "        [0.9257, 0.7095, 0.8421,  ..., 0.7359, 0.7640, 0.7821],\n",
       "        ...,\n",
       "        [0.9251, 0.7017, 0.8335,  ..., 0.7628, 0.7763, 0.7630],\n",
       "        [0.9216, 0.6988, 0.8443,  ..., 0.7445, 0.7536, 0.6975],\n",
       "        [0.9272, 0.7061, 0.8407,  ..., 0.7397, 0.7848, 0.7020]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GNNExample(1, 2866, 650, 50, 650)\n",
    "lat = model(z)\n",
    "lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e914360e-5178-4160-9461-2701cfa0524e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "650"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56fb6c3-0b5e-4068-8638-a2b7c5f9f37d",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c34b3b-c3e2-4d25-984e-b8ebb80b9539",
   "metadata": {},
   "source": [
    "## PROOF THAT DATA LOADER CAN ACTUALLY HANDLE DATA BATCHES!!\n",
    "\n",
    "The problem here was that if we already have a dataloader with batches of size 32, if we were to unroll these batches to make a bigger dataloader without batches (so all data in one batch), how would this be done? Luckily, the library accounts for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "29357e15-d03f-403c-aadf-f300fb7e428d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph 1:\n",
      "Data(edge_index=[2, 2])\n",
      "Graph 2:\n",
      "Data(edge_index=[2, 2])\n",
      "Graph 3:\n",
      "Data(edge_index=[2, 2])\n",
      "First data loader\n",
      "DataBatch(edge_index=[2, 4], batch=[4], ptr=[3])\n",
      "DataBatch(edge_index=[2, 2], batch=[2], ptr=[2])\n",
      "Second data loader\n",
      "DataBatch(edge_index=[2, 6], batch=[6])\n",
      "tensor([[0, 1, 2, 3, 4, 5],\n",
      "        [1, 0, 3, 2, 5, 4]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_geometric.data as data\n",
    "\n",
    "# Define the edges for the first graph\n",
    "edges1 = torch.tensor([[0,1], [1,0]])\n",
    "\n",
    "\n",
    "# Create data objects for each graph\n",
    "graph1 = data.Data(edge_index=edges1)\n",
    "graph2 = data.Data(edge_index=edges1)\n",
    "graph3 = data.Data(edge_index=edges1)\n",
    "\n",
    "# Print the graphs\n",
    "print(\"Graph 1:\")\n",
    "print(graph1)\n",
    "print(\"Graph 2:\")\n",
    "print(graph2)\n",
    "print(\"Graph 3:\")\n",
    "print(graph3)\n",
    "\n",
    "x = [graph1, graph2, graph3]\n",
    "\n",
    "print(\"First data loader\")\n",
    "d = DataLoader(x, batch_size = 2)\n",
    "\n",
    "xs = []\n",
    "for i in d:\n",
    "    print(i)\n",
    "    xs +=[i]\n",
    "\n",
    "print(\"Second data loader\")\n",
    "d2 = DataLoader(xs, batch_size = 3)\n",
    "for i in d2:\n",
    "    print(i)\n",
    "    print(i.edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a5c792-06f9-4c97-ad12-2cf24f7e5a4d",
   "metadata": {},
   "source": [
    "------------------\n",
    "---------------------\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5edaea33-fbce-48a8-b2f3-a790764df602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.0129],\n",
      "        [3.5161],\n",
      "        [3.5418]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import GCNConv, SimpleConv\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# adjacency matrix of graph\n",
    "edge_index = torch.tensor([[0,1,1,2], [1,0,2,1]], dtype=torch.long)\n",
    "\n",
    "# features for each node\n",
    "x = torch.tensor([[1], [2], [3]], dtype=torch.float)\n",
    "\n",
    "# simpleconv declaration\n",
    "in_channels = 1  # Number of input features per node\n",
    "out_channels = 1  # Number of output features per node\n",
    "conv = GCNConv(in_channels, out_channels)\n",
    "\n",
    "# process it\n",
    "x = conv(x, edge_index)\n",
    "\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8c35226-efca-49f9-b239-c5544e5896cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle \n",
    "import torch\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "somepath = os.path.abspath(\n",
    "    os.path.join(current_directory, '..', 'Data', 'RNA_dataset_graph_R3.pkl'))\n",
    "\n",
    "with open(somepath, 'rb') as f:\n",
    "    loaded_object = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "151b090d-3711-4a97-940b-d16e6b5d28c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.1000],\n",
       "        [4.3800],\n",
       "        [3.0700],\n",
       "        ...,\n",
       "        [8.6800],\n",
       "        [7.0900],\n",
       "        [4.9400]], dtype=torch.float64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = loaded_object[0]\n",
    "features = []\n",
    "for node, attr in G.nodes(data = True):\n",
    "    features += [[attr['node_attr']]]\n",
    "features = torch.tensor(features)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "50a78ed9-0a05-456f-91d2-da2d1235b8fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2866, 1], edge_index=[2, 90932])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "data = None\n",
    "\n",
    "G = loaded_object[0]\n",
    "# we enumerate each node in a dict\n",
    "node_to_index = {node: idx for idx, node in enumerate(G.nodes())}\n",
    "\n",
    "edge_index = torch.tensor([(node_to_index[edge[0]], node_to_index[edge[1]]) for edge in G.edges()] +\n",
    "                 [(node_to_index[edge[1]], node_to_index[edge[0]]) for edge in G.edges()]).t().contiguous()\n",
    "data = Data(x= features, edge_index = edge_index)\n",
    "data.validate(raise_on_error=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0e6ee9d4-3fa5-4ac9-a783-3064ef8bd35e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2866, 1], edge_index=[2, 90932])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f5eceabc-d3e4-41ee-ba18-0e3c04d26146",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = data.x / max(data.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2c94a32d-d321-4e97-972c-62183fff612e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4743],\n",
       "        [0.3406],\n",
       "        [0.2387],\n",
       "        ...,\n",
       "        [0.6750],\n",
       "        [0.5513],\n",
       "        [0.3841]], dtype=torch.float64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "52ce5683-98f3-4faa-b0e1-6b45f237ff4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2250, 0.1616, 0.1132,  ..., 0.3202, 0.2615, 0.1822],\n",
       "        [0.1616, 0.1160, 0.0813,  ..., 0.2299, 0.1878, 0.1308],\n",
       "        [0.1132, 0.0813, 0.0570,  ..., 0.1611, 0.1316, 0.0917],\n",
       "        ...,\n",
       "        [0.3202, 0.2299, 0.1611,  ..., 0.4556, 0.3721, 0.2593],\n",
       "        [0.2615, 0.1878, 0.1316,  ..., 0.3721, 0.3040, 0.2118],\n",
       "        [0.1822, 0.1308, 0.0917,  ..., 0.2593, 0.2118, 0.1476]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recons_matrix = torch.matmul(xx, xx.t())\n",
    "recons_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "66abf63a-194d-4314-a43a-b113a82aca64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   1,  282,  554,  ..., 2702, 2706, 2708])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_index[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6d69dc21-f3c6-49af-a40c-97aee559116a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1),\n",
       " (0, 282),\n",
       " (0, 554),\n",
       " (0, 665),\n",
       " (0, 29),\n",
       " (0, 1213),\n",
       " (0, 1102),\n",
       " (0, 366),\n",
       " (0, 145),\n",
       " (0, 67),\n",
       " (0, 1014),\n",
       " (0, 1134),\n",
       " (0, 523),\n",
       " (0, 1163),\n",
       " (0, 213),\n",
       " (0, 640),\n",
       " (0, 452),\n",
       " (0, 277),\n",
       " (0, 963),\n",
       " (0, 152),\n",
       " (0, 512),\n",
       " (0, 479),\n",
       " (0, 409),\n",
       " (0, 1669),\n",
       " (0, 545),\n",
       " (0, 693),\n",
       " (0, 830),\n",
       " (0, 669),\n",
       " (0, 308),\n",
       " (0, 1432),\n",
       " (0, 270),\n",
       " (0, 86),\n",
       " (0, 820),\n",
       " (0, 684),\n",
       " (0, 293),\n",
       " (0, 1126),\n",
       " (0, 392),\n",
       " (0, 135),\n",
       " (0, 1433),\n",
       " (0, 1827),\n",
       " (0, 1016),\n",
       " (0, 1064),\n",
       " (0, 924),\n",
       " (0, 240),\n",
       " (0, 1291),\n",
       " (0, 54),\n",
       " (0, 142),\n",
       " (0, 42),\n",
       " (0, 95),\n",
       " (0, 623),\n",
       " (0, 1274),\n",
       " (0, 651),\n",
       " (0, 1476),\n",
       " (0, 388),\n",
       " (0, 620),\n",
       " (0, 1891),\n",
       " (0, 1118),\n",
       " (0, 890),\n",
       " (0, 1235),\n",
       " (0, 1399),\n",
       " (0, 526),\n",
       " (0, 1680),\n",
       " (0, 126),\n",
       " (0, 7),\n",
       " (0, 214),\n",
       " (0, 197),\n",
       " (0, 389),\n",
       " (0, 348),\n",
       " (0, 472),\n",
       " (0, 1574),\n",
       " (0, 1690),\n",
       " (0, 511),\n",
       " (0, 1105),\n",
       " (0, 1089),\n",
       " (0, 296),\n",
       " (0, 547),\n",
       " (0, 99),\n",
       " (0, 246),\n",
       " (0, 1221),\n",
       " (0, 438),\n",
       " (0, 426),\n",
       " (0, 1369),\n",
       " (0, 995),\n",
       " (0, 1212),\n",
       " (0, 807),\n",
       " (0, 2823),\n",
       " (0, 586),\n",
       " (0, 801),\n",
       " (0, 1234),\n",
       " (0, 160),\n",
       " (0, 962),\n",
       " (0, 1583),\n",
       " (0, 642),\n",
       " (0, 628),\n",
       " (0, 1553),\n",
       " (0, 64),\n",
       " (0, 735),\n",
       " (0, 1631),\n",
       " (0, 321),\n",
       " (0, 2039),\n",
       " (0, 690),\n",
       " (0, 305),\n",
       " (0, 177),\n",
       " (0, 1179),\n",
       " (0, 51),\n",
       " (0, 155),\n",
       " (0, 222),\n",
       " (0, 101),\n",
       " (0, 631),\n",
       " (0, 332),\n",
       " (0, 861),\n",
       " (0, 610),\n",
       " (0, 420),\n",
       " (0, 459),\n",
       " (0, 2404),\n",
       " (0, 92),\n",
       " (0, 93),\n",
       " (0, 650),\n",
       " (0, 290),\n",
       " (0, 894),\n",
       " (0, 582),\n",
       " (0, 954),\n",
       " (0, 741),\n",
       " (0, 176),\n",
       " (0, 515),\n",
       " (0, 413),\n",
       " (0, 1558),\n",
       " (0, 346),\n",
       " (0, 2052),\n",
       " (0, 659),\n",
       " (0, 262),\n",
       " (0, 788),\n",
       " (0, 1062),\n",
       " (0, 47),\n",
       " (0, 592),\n",
       " (0, 1902),\n",
       " (0, 1012),\n",
       " (0, 809),\n",
       " (1, 1352),\n",
       " (1, 1545),\n",
       " (1, 1286),\n",
       " (1, 545),\n",
       " (1, 302),\n",
       " (1, 1102),\n",
       " (1, 565),\n",
       " (1, 305),\n",
       " (1, 97),\n",
       " (1, 296),\n",
       " (1, 144),\n",
       " (1, 1691),\n",
       " (1, 214),\n",
       " (1, 95),\n",
       " (1, 88),\n",
       " (1, 807),\n",
       " (1, 655),\n",
       " (1, 348),\n",
       " (1, 1335),\n",
       " (1, 74),\n",
       " (1, 332),\n",
       " (2, 3),\n",
       " (2, 240),\n",
       " (2, 1268),\n",
       " (2, 59),\n",
       " (2, 489),\n",
       " (2, 1157),\n",
       " (2, 1965),\n",
       " (2, 2068),\n",
       " (2, 453),\n",
       " (2, 865),\n",
       " (2, 88),\n",
       " (2, 382),\n",
       " (2, 1041),\n",
       " (2, 575),\n",
       " (2, 17),\n",
       " (2, 53),\n",
       " (2, 217),\n",
       " (2, 1232),\n",
       " (2, 946),\n",
       " (2, 200),\n",
       " (2, 2362),\n",
       " (2, 1957),\n",
       " (2, 698),\n",
       " (2, 1040),\n",
       " (2, 611),\n",
       " (2, 126),\n",
       " (2, 691),\n",
       " (2, 1051),\n",
       " (2, 317),\n",
       " (2, 1028),\n",
       " (2, 204),\n",
       " (2, 152),\n",
       " (2, 1313),\n",
       " (2, 256),\n",
       " (2, 2252),\n",
       " (2, 768),\n",
       " (2, 215),\n",
       " (2, 128),\n",
       " (2, 218),\n",
       " (2, 2115),\n",
       " (2, 1706),\n",
       " (2, 2503),\n",
       " (2, 655),\n",
       " (2, 567),\n",
       " (2, 828),\n",
       " (2, 926),\n",
       " (2, 323),\n",
       " (2, 2097),\n",
       " (2, 195),\n",
       " (2, 1414),\n",
       " (3, 1033),\n",
       " (3, 663),\n",
       " (3, 52),\n",
       " (3, 100),\n",
       " (3, 372),\n",
       " (3, 121),\n",
       " (3, 2396),\n",
       " (3, 1174),\n",
       " (3, 1573),\n",
       " (3, 135),\n",
       " (3, 321),\n",
       " (3, 2061),\n",
       " (3, 1261),\n",
       " (3, 1414),\n",
       " (3, 202),\n",
       " (3, 899),\n",
       " (3, 95),\n",
       " (3, 422),\n",
       " (3, 468),\n",
       " (3, 1765),\n",
       " (3, 1658),\n",
       " (3, 211),\n",
       " (3, 1210),\n",
       " (3, 714),\n",
       " (3, 694),\n",
       " (3, 1971),\n",
       " (3, 567),\n",
       " (3, 138),\n",
       " (3, 429),\n",
       " (3, 335),\n",
       " (3, 215),\n",
       " (3, 73),\n",
       " (3, 1281),\n",
       " (3, 894),\n",
       " (3, 145),\n",
       " (3, 1240),\n",
       " (3, 1410),\n",
       " (3, 1611),\n",
       " (3, 713),\n",
       " (3, 60),\n",
       " (3, 1131),\n",
       " (3, 274),\n",
       " (3, 784),\n",
       " (3, 591),\n",
       " (4, 5),\n",
       " (4, 472),\n",
       " (4, 548),\n",
       " (4, 626),\n",
       " (4, 1853),\n",
       " (4, 311),\n",
       " (4, 659),\n",
       " (4, 158),\n",
       " (4, 12),\n",
       " (4, 1709),\n",
       " (4, 295),\n",
       " (4, 74),\n",
       " (4, 240),\n",
       " (4, 51),\n",
       " (4, 719),\n",
       " (4, 1118),\n",
       " (4, 272),\n",
       " (4, 542),\n",
       " (4, 171),\n",
       " (4, 2323),\n",
       " (4, 906),\n",
       " (4, 332),\n",
       " (4, 533),\n",
       " (5, 342),\n",
       " (5, 1383),\n",
       " (5, 251),\n",
       " (5, 142),\n",
       " (5, 897),\n",
       " (5, 176),\n",
       " (5, 392),\n",
       " (5, 548),\n",
       " (5, 74),\n",
       " (5, 1089),\n",
       " (5, 272),\n",
       " (5, 1918),\n",
       " (5, 138),\n",
       " (5, 1878),\n",
       " (5, 814),\n",
       " (5, 256),\n",
       " (5, 1007),\n",
       " (5, 544),\n",
       " (5, 1617),\n",
       " (5, 270),\n",
       " (5, 2469),\n",
       " (5, 1320),\n",
       " (5, 493),\n",
       " (5, 1109),\n",
       " (5, 1163),\n",
       " (5, 1619),\n",
       " (5, 155),\n",
       " (5, 906),\n",
       " (5, 483),\n",
       " (5, 547),\n",
       " (5, 542),\n",
       " (5, 1836),\n",
       " (5, 645),\n",
       " (5, 1229),\n",
       " (5, 2033),\n",
       " (5, 292),\n",
       " (5, 1387),\n",
       " (5, 709),\n",
       " (5, 2403),\n",
       " (5, 1480),\n",
       " (5, 707),\n",
       " (5, 1134),\n",
       " (5, 424),\n",
       " (5, 553),\n",
       " (5, 809),\n",
       " (5, 879),\n",
       " (5, 927),\n",
       " (5, 1609),\n",
       " (5, 1445),\n",
       " (5, 999),\n",
       " (5, 297),\n",
       " (5, 332),\n",
       " (5, 207),\n",
       " (5, 723),\n",
       " (5, 211),\n",
       " (5, 320),\n",
       " (5, 472),\n",
       " (5, 1064),\n",
       " (5, 1244),\n",
       " (5, 271),\n",
       " (5, 148),\n",
       " (5, 152),\n",
       " (5, 1102),\n",
       " (5, 729),\n",
       " (5, 275),\n",
       " (5, 322),\n",
       " (5, 1273),\n",
       " (5, 104),\n",
       " (5, 896),\n",
       " (5, 1214),\n",
       " (5, 973),\n",
       " (5, 2052),\n",
       " (5, 819),\n",
       " (5, 1044),\n",
       " (5, 183),\n",
       " (5, 924),\n",
       " (5, 346),\n",
       " (5, 1057),\n",
       " (5, 1393),\n",
       " (5, 581),\n",
       " (5, 92),\n",
       " (5, 190),\n",
       " (5, 1243),\n",
       " (5, 249),\n",
       " (5, 430),\n",
       " (5, 96),\n",
       " (5, 389),\n",
       " (5, 735),\n",
       " (5, 1284),\n",
       " (5, 1256),\n",
       " (5, 417),\n",
       " (5, 47),\n",
       " (5, 574),\n",
       " (5, 319),\n",
       " (5, 1545),\n",
       " (5, 1469),\n",
       " (5, 23),\n",
       " (5, 317),\n",
       " (5, 85),\n",
       " (5, 635),\n",
       " (5, 1071),\n",
       " (5, 610),\n",
       " (5, 730),\n",
       " (5, 523),\n",
       " (5, 253),\n",
       " (5, 1166),\n",
       " (5, 236),\n",
       " (5, 265),\n",
       " (5, 1902),\n",
       " (5, 240),\n",
       " (5, 2229),\n",
       " (5, 628),\n",
       " (5, 1118),\n",
       " (5, 915),\n",
       " (5, 2101),\n",
       " (5, 808),\n",
       " (5, 1255),\n",
       " (5, 1433),\n",
       " (5, 209),\n",
       " (5, 1487),\n",
       " (5, 51),\n",
       " (5, 296),\n",
       " (5, 1161),\n",
       " (5, 651),\n",
       " (5, 701),\n",
       " (5, 202),\n",
       " (5, 644),\n",
       " (5, 1618),\n",
       " (6, 7),\n",
       " (6, 397),\n",
       " (6, 261),\n",
       " (6, 500),\n",
       " (6, 605),\n",
       " (6, 647),\n",
       " (6, 251),\n",
       " (6, 290),\n",
       " (6, 700),\n",
       " (6, 790),\n",
       " (6, 1280),\n",
       " (6, 340),\n",
       " (6, 515),\n",
       " (6, 1783),\n",
       " (6, 341),\n",
       " (6, 708),\n",
       " (6, 486),\n",
       " (6, 728),\n",
       " (6, 1324),\n",
       " (6, 578),\n",
       " (6, 231),\n",
       " (6, 308),\n",
       " (6, 1553),\n",
       " (6, 319),\n",
       " (6, 1119),\n",
       " (6, 1615),\n",
       " (6, 461),\n",
       " (6, 690),\n",
       " (6, 460),\n",
       " (6, 2491),\n",
       " (6, 998),\n",
       " (6, 2559),\n",
       " (6, 814),\n",
       " (6, 424),\n",
       " (6, 1990),\n",
       " (6, 1886),\n",
       " (6, 1012),\n",
       " (6, 1052),\n",
       " (6, 206),\n",
       " (6, 964),\n",
       " (6, 2600),\n",
       " (6, 1239),\n",
       " (6, 173),\n",
       " (6, 1540),\n",
       " (6, 353),\n",
       " (6, 222),\n",
       " (6, 662),\n",
       " (6, 152),\n",
       " (6, 734),\n",
       " (6, 1494),\n",
       " (6, 497),\n",
       " (6, 579),\n",
       " (6, 188),\n",
       " (6, 54),\n",
       " (6, 666),\n",
       " (6, 108),\n",
       " (6, 840),\n",
       " (6, 1262),\n",
       " (6, 284),\n",
       " (6, 1764),\n",
       " (6, 22),\n",
       " (6, 709),\n",
       " (6, 1163),\n",
       " (6, 1149),\n",
       " (6, 542),\n",
       " (6, 1185),\n",
       " (6, 1195),\n",
       " (6, 1179),\n",
       " (6, 220),\n",
       " (6, 857),\n",
       " (6, 1399),\n",
       " (6, 1241),\n",
       " (6, 121),\n",
       " (6, 217),\n",
       " (6, 427),\n",
       " (6, 1823),\n",
       " (6, 1291),\n",
       " (6, 246),\n",
       " (6, 1807),\n",
       " (6, 590),\n",
       " (6, 292),\n",
       " (6, 282),\n",
       " (6, 205),\n",
       " (6, 1568),\n",
       " (6, 787),\n",
       " (6, 259),\n",
       " (6, 1688),\n",
       " (6, 860),\n",
       " (6, 411),\n",
       " (6, 683),\n",
       " (6, 219),\n",
       " (6, 373),\n",
       " (6, 1403),\n",
       " (6, 50),\n",
       " (6, 1074),\n",
       " (6, 892),\n",
       " (6, 805),\n",
       " (6, 535),\n",
       " (6, 202),\n",
       " (6, 2589),\n",
       " (6, 524),\n",
       " (6, 1905),\n",
       " (6, 95),\n",
       " (6, 1458),\n",
       " (6, 762),\n",
       " (6, 475),\n",
       " (6, 1219),\n",
       " (6, 432),\n",
       " (6, 342),\n",
       " (6, 936),\n",
       " (6, 977),\n",
       " (6, 153),\n",
       " (6, 867),\n",
       " (6, 129),\n",
       " (6, 273),\n",
       " (6, 210),\n",
       " (6, 759),\n",
       " (6, 620),\n",
       " (6, 1797),\n",
       " (6, 2312),\n",
       " (6, 1539),\n",
       " (6, 1552),\n",
       " (6, 69),\n",
       " (6, 2178),\n",
       " (6, 88),\n",
       " (6, 830),\n",
       " (6, 1183),\n",
       " (6, 484),\n",
       " (6, 812),\n",
       " (6, 2032),\n",
       " (6, 291),\n",
       " (6, 2272),\n",
       " (6, 144),\n",
       " (6, 1469),\n",
       " (6, 533),\n",
       " (6, 115),\n",
       " (6, 1243),\n",
       " (6, 1846),\n",
       " (6, 1173),\n",
       " (6, 1112),\n",
       " (6, 1543),\n",
       " (6, 304),\n",
       " (6, 211),\n",
       " (7, 94),\n",
       " (7, 276),\n",
       " (7, 416),\n",
       " (7, 1064),\n",
       " (7, 1247),\n",
       " (7, 805),\n",
       " (7, 620),\n",
       " (7, 1414),\n",
       " (7, 553),\n",
       " (7, 955),\n",
       " (7, 1054),\n",
       " (7, 478),\n",
       " (7, 500),\n",
       " (7, 191),\n",
       " (7, 291),\n",
       " (7, 1640),\n",
       " (7, 611),\n",
       " (7, 355),\n",
       " (7, 1553),\n",
       " (7, 694),\n",
       " (7, 2187),\n",
       " (7, 200),\n",
       " (7, 740),\n",
       " (7, 443),\n",
       " (7, 1587),\n",
       " (7, 866),\n",
       " (7, 513),\n",
       " (7, 527),\n",
       " (7, 901),\n",
       " (7, 348),\n",
       " (7, 1583),\n",
       " (7, 516),\n",
       " (7, 261),\n",
       " (7, 1930),\n",
       " (7, 115),\n",
       " (7, 657),\n",
       " (7, 776),\n",
       " (7, 972),\n",
       " (7, 833),\n",
       " (7, 718),\n",
       " (7, 67),\n",
       " (7, 1578),\n",
       " (7, 163),\n",
       " (7, 655),\n",
       " (7, 1817),\n",
       " (7, 1825),\n",
       " (7, 969),\n",
       " (7, 2412),\n",
       " (7, 2467),\n",
       " (7, 594),\n",
       " (7, 87),\n",
       " (7, 108),\n",
       " (7, 418),\n",
       " (7, 946),\n",
       " (7, 1860),\n",
       " (7, 551),\n",
       " (7, 1633),\n",
       " (7, 449),\n",
       " (7, 98),\n",
       " (7, 272),\n",
       " (7, 160),\n",
       " (7, 1091),\n",
       " (7, 528),\n",
       " (7, 601),\n",
       " (7, 965),\n",
       " (7, 92),\n",
       " (7, 867),\n",
       " (7, 622),\n",
       " (7, 781),\n",
       " (7, 253),\n",
       " (7, 51),\n",
       " (7, 334),\n",
       " (7, 927),\n",
       " (7, 843),\n",
       " (7, 1349),\n",
       " (7, 1346),\n",
       " (7, 1819),\n",
       " (7, 246),\n",
       " (7, 211),\n",
       " (7, 222),\n",
       " (7, 894),\n",
       " (7, 1179),\n",
       " (7, 2128),\n",
       " (7, 1458),\n",
       " (7, 1476),\n",
       " (7, 446),\n",
       " (7, 73),\n",
       " (7, 294),\n",
       " (7, 340),\n",
       " (7, 214),\n",
       " (7, 287),\n",
       " (7, 374),\n",
       " (7, 317),\n",
       " (7, 1085),\n",
       " (7, 1243),\n",
       " (7, 1102),\n",
       " (7, 301),\n",
       " (7, 1445),\n",
       " (7, 705),\n",
       " (7, 208),\n",
       " (7, 2048),\n",
       " (7, 1621),\n",
       " (7, 172),\n",
       " (7, 679),\n",
       " (7, 1461),\n",
       " (7, 1249),\n",
       " (7, 1848),\n",
       " (7, 1248),\n",
       " (7, 413),\n",
       " (7, 42),\n",
       " (7, 1365),\n",
       " (7, 2011),\n",
       " (7, 133),\n",
       " (7, 556),\n",
       " (7, 662),\n",
       " (7, 2040),\n",
       " (7, 275),\n",
       " (7, 1879),\n",
       " (7, 928),\n",
       " (7, 52),\n",
       " (7, 859),\n",
       " (7, 296),\n",
       " (7, 512),\n",
       " (7, 1112),\n",
       " (7, 807),\n",
       " (7, 686),\n",
       " (7, 669),\n",
       " (7, 967),\n",
       " (7, 64),\n",
       " (7, 658),\n",
       " (7, 2330),\n",
       " (7, 625),\n",
       " (7, 1173),\n",
       " (7, 458),\n",
       " (7, 907),\n",
       " (7, 522),\n",
       " (7, 586),\n",
       " (7, 997),\n",
       " (7, 1174),\n",
       " (7, 197),\n",
       " (7, 138),\n",
       " (7, 2468),\n",
       " (7, 136),\n",
       " (7, 1187),\n",
       " (7, 852),\n",
       " (7, 2223),\n",
       " (7, 526),\n",
       " (7, 265),\n",
       " (7, 640),\n",
       " (7, 1193),\n",
       " (7, 93),\n",
       " (7, 899),\n",
       " (7, 332),\n",
       " (7, 308),\n",
       " (7, 456),\n",
       " (7, 511),\n",
       " (7, 459),\n",
       " (7, 60),\n",
       " (7, 210),\n",
       " (7, 389),\n",
       " (7, 411),\n",
       " (7, 1067),\n",
       " (7, 1014),\n",
       " (7, 2293),\n",
       " (7, 2232),\n",
       " (7, 304),\n",
       " (7, 1369),\n",
       " (7, 277),\n",
       " (7, 1336),\n",
       " (7, 714),\n",
       " (7, 433),\n",
       " (7, 260),\n",
       " (7, 1471),\n",
       " (7, 998),\n",
       " (7, 554),\n",
       " (7, 85),\n",
       " (7, 1140),\n",
       " (7, 820),\n",
       " (7, 1166),\n",
       " (7, 704),\n",
       " (7, 644),\n",
       " (7, 305),\n",
       " (7, 1380),\n",
       " (7, 166),\n",
       " (7, 121),\n",
       " (7, 1012),\n",
       " (7, 609),\n",
       " (7, 909),\n",
       " (7, 700),\n",
       " (7, 1463),\n",
       " (7, 444),\n",
       " (7, 1891),\n",
       " (7, 366),\n",
       " (7, 240),\n",
       " (7, 578),\n",
       " (7, 176),\n",
       " (7, 1284),\n",
       " (7, 1530),\n",
       " (7, 320),\n",
       " (7, 596),\n",
       " (7, 1770),\n",
       " (7, 174),\n",
       " (7, 592),\n",
       " (7, 978),\n",
       " (8, 9),\n",
       " (8, 1161),\n",
       " (8, 1433),\n",
       " (8, 651),\n",
       " (8, 1847),\n",
       " (8, 654),\n",
       " (8, 22),\n",
       " (8, 1293),\n",
       " (8, 1561),\n",
       " (8, 204),\n",
       " (8, 1182),\n",
       " (8, 1221),\n",
       " (8, 679),\n",
       " (8, 296),\n",
       " (8, 1314),\n",
       " (8, 1222),\n",
       " (8, 1449),\n",
       " (8, 999),\n",
       " (8, 475),\n",
       " (8, 533),\n",
       " (8, 422),\n",
       " (8, 527),\n",
       " (8, 598),\n",
       " (8, 69),\n",
       " (8, 2251),\n",
       " (8, 1028),\n",
       " (8, 875),\n",
       " (8, 92),\n",
       " (8, 389),\n",
       " (8, 353),\n",
       " (8, 62),\n",
       " (8, 1453),\n",
       " (8, 694),\n",
       " (8, 433),\n",
       " (8, 1934),\n",
       " (8, 700),\n",
       " (8, 1096),\n",
       " (8, 16),\n",
       " (8, 424),\n",
       " (8, 1163),\n",
       " (8, 2429),\n",
       " (8, 1149),\n",
       " (8, 229),\n",
       " (8, 1583),\n",
       " (8, 397),\n",
       " (8, 279),\n",
       " (8, 1391),\n",
       " (8, 542),\n",
       " (8, 1249),\n",
       " (8, 285),\n",
       " (8, 2481),\n",
       " (8, 2647),\n",
       " (9, 624),\n",
       " (9, 774),\n",
       " (9, 1011),\n",
       " (9, 1126),\n",
       " (9, 1118),\n",
       " (9, 832),\n",
       " (9, 829),\n",
       " (9, 715),\n",
       " (9, 1372),\n",
       " (9, 1427),\n",
       " (9, 125),\n",
       " (9, 1369),\n",
       " (9, 808),\n",
       " (9, 936),\n",
       " (9, 956),\n",
       " (9, 45),\n",
       " (9, 1194),\n",
       " (9, 282),\n",
       " (9, 2194),\n",
       " (9, 1526),\n",
       " (9, 93),\n",
       " (9, 548),\n",
       " (9, 1062),\n",
       " (9, 925),\n",
       " (9, 693),\n",
       " (9, 415),\n",
       " (9, 212),\n",
       " (9, 1412),\n",
       " (9, 1701),\n",
       " (9, 1045),\n",
       " (9, 1730),\n",
       " (9, 142),\n",
       " (9, 435),\n",
       " (9, 1249),\n",
       " (9, 2451),\n",
       " (9, 1320),\n",
       " (9, 924),\n",
       " (9, 1440),\n",
       " (9, 211),\n",
       " (9, 30),\n",
       " (9, 285),\n",
       " (9, 177),\n",
       " (9, 149),\n",
       " (9, 488),\n",
       " (9, 272),\n",
       " (9, 2494),\n",
       " (9, 890),\n",
       " (9, 2576),\n",
       " (9, 726),\n",
       " (9, 289),\n",
       " (9, 275),\n",
       " (9, 2168),\n",
       " (9, 809),\n",
       " (9, 1382),\n",
       " (9, 155),\n",
       " (9, 1056),\n",
       " (9, 183),\n",
       " (9, 1561),\n",
       " (9, 526),\n",
       " (9, 170),\n",
       " (9, 1500),\n",
       " (9, 1433),\n",
       " (9, 999),\n",
       " (9, 1197),\n",
       " (9, 1394),\n",
       " (9, 1273),\n",
       " (9, 1510),\n",
       " (9, 394),\n",
       " (9, 262),\n",
       " (9, 678),\n",
       " (9, 2715),\n",
       " (9, 1283),\n",
       " (9, 1096),\n",
       " (9, 545),\n",
       " (9, 619),\n",
       " (9, 88),\n",
       " (9, 28),\n",
       " (9, 1285),\n",
       " (9, 768),\n",
       " (9, 586),\n",
       " (9, 2083),\n",
       " (9, 582),\n",
       " (9, 95),\n",
       " (9, 993),\n",
       " (9, 261),\n",
       " (9, 659),\n",
       " (9, 1243),\n",
       " (9, 2076),\n",
       " (9, 654),\n",
       " (9, 2626),\n",
       " (9, 788),\n",
       " (9, 64),\n",
       " (9, 2369),\n",
       " (9, 333),\n",
       " (9, 856),\n",
       " (9, 322),\n",
       " (9, 1137),\n",
       " (9, 1144),\n",
       " (9, 1220),\n",
       " (9, 1519),\n",
       " (9, 1847),\n",
       " (9, 959),\n",
       " (9, 129),\n",
       " (9, 2257),\n",
       " (9, 875),\n",
       " (9, 73),\n",
       " (9, 1824),\n",
       " (9, 1615),\n",
       " (9, 1222),\n",
       " (9, 798),\n",
       " (9, 949),\n",
       " (9, 814),\n",
       " (9, 896),\n",
       " (9, 411),\n",
       " (9, 42),\n",
       " (9, 438),\n",
       " (9, 439),\n",
       " (9, 594),\n",
       " (9, 552),\n",
       " (9, 563),\n",
       " (9, 781),\n",
       " (9, 428),\n",
       " (9, 2251),\n",
       " (9, 822),\n",
       " (9, 610),\n",
       " (9, 575),\n",
       " (9, 509),\n",
       " (9, 1675),\n",
       " (9, 1681),\n",
       " (9, 1077),\n",
       " (9, 638),\n",
       " (9, 1600),\n",
       " (9, 2101),\n",
       " (9, 1698),\n",
       " (9, 370),\n",
       " (9, 455),\n",
       " (9, 1832),\n",
       " (9, 1163),\n",
       " (9, 1530),\n",
       " (9, 1584),\n",
       " (9, 205),\n",
       " (9, 2023),\n",
       " (9, 1329),\n",
       " (9, 184),\n",
       " (9, 259),\n",
       " (9, 965),\n",
       " (9, 251),\n",
       " (9, 1221),\n",
       " (9, 951),\n",
       " (9, 1558),\n",
       " (9, 486),\n",
       " (9, 2081),\n",
       " (9, 332),\n",
       " (9, 835),\n",
       " (9, 1080),\n",
       " (9, 384),\n",
       " (9, 1020),\n",
       " (9, 200),\n",
       " (9, 560),\n",
       " (9, 353),\n",
       " (9, 2402),\n",
       " (9, 741),\n",
       " (9, 1129),\n",
       " (9, 1442),\n",
       " (9, 1417),\n",
       " (9, 1684),\n",
       " (9, 416),\n",
       " (9, 825),\n",
       " (9, 1379),\n",
       " (9, 713),\n",
       " (9, 490),\n",
       " (9, 92),\n",
       " (9, 810),\n",
       " (9, 16),\n",
       " (9, 653),\n",
       " (9, 296),\n",
       " (9, 651),\n",
       " (9, 1010),\n",
       " (9, 2467),\n",
       " (9, 623),\n",
       " (9, 292),\n",
       " (9, 392),\n",
       " (9, 628),\n",
       " (9, 1306),\n",
       " (9, 977),\n",
       " (9, 2662),\n",
       " (9, 1240),\n",
       " (9, 105),\n",
       " (9, 1495),\n",
       " (9, 945),\n",
       " (9, 1227),\n",
       " (9, 724),\n",
       " (9, 210),\n",
       " (9, 121),\n",
       " (9, 613),\n",
       " (9, 1161),\n",
       " (9, 1141),\n",
       " ...]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges = [(data.edge_index[0][i].item(), data.edge_index[1][i].item()) for i in range(len(data.edge_index[0]))]\n",
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0cf983c3-0f0c-42f9-86e2-d56ffb190b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjMatrix = torch.zeros(len(xx), len(xx))\n",
    "adjMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "21b3ae75-8534-4862-bb05-af148a814dec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0.,  ..., 0., 0., 0.],\n",
       "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in edges:\n",
    "    adjMatrix[i[0]][i[1]] = 1\n",
    "adjMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "298ad01c-351a-4f84-884d-1b19745fff14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(252.0417, dtype=torch.float64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crit = nn.CrossEntropyLoss(reduction='mean')\n",
    "crit(recons_matrix, adjMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "800665b4-cbe1-4cc9-8807-b4c45884e620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_space.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6c316c68-e3ca-4422-8447-54062a89d4e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.2105e-01, 5.0318e-01, 6.5654e-01,  ..., 9.9106e-01, 1.2716e-01,\n",
       "         8.4550e-01],\n",
       "        [2.8750e-01, 5.1376e-02, 1.7650e-01,  ..., 6.2799e-02, 8.7049e-01,\n",
       "         2.3504e-02],\n",
       "        [9.5096e-01, 7.1031e-01, 6.5141e-01,  ..., 4.1342e-01, 1.5894e-01,\n",
       "         4.6340e-01],\n",
       "        ...,\n",
       "        [6.7209e-01, 7.9483e-01, 4.2482e-02,  ..., 7.3005e-01, 7.0396e-01,\n",
       "         9.0176e-01],\n",
       "        [4.1348e-01, 1.8075e-01, 4.0985e-01,  ..., 4.1981e-01, 1.3872e-01,\n",
       "         3.6643e-01],\n",
       "        [6.8927e-04, 3.7078e-01, 8.3436e-01,  ..., 7.5807e-01, 8.7345e-01,\n",
       "         1.9088e-01]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_space = torch.rand(100,500)\n",
    "latent_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9161d5bc-4232-474e-bc66-d69aec50af82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlsxwriter\n",
    "\n",
    "row = 1\n",
    "col = 1\n",
    "\n",
    "workbook = xlsxwriter.Workbook('Latent_space.xlsx')\n",
    "worksheet = workbook.add_worksheet()\n",
    "\n",
    "bold_format = workbook.add_format({'bold': True, 'bg_color': '#DDDDDD'})\n",
    "\n",
    "for i in range(latent_space.shape[1]):\n",
    "    worksheet.write(0, i + 1, 'Lat. '+str(i), bold_format)\n",
    "\n",
    "for i in range(latent_space.shape[0]):\n",
    "    worksheet.write(i + 1, 0, 'Pat. '+str(i), bold_format)\n",
    "    \n",
    "\n",
    "for xs in latent_space:\n",
    "    for x in xs:\n",
    "        red_component = max(int(x * 255), 30)\n",
    "        blue_component = max(int((1 - x) * 255), 30)\n",
    "        purple_hex = '#{:02X}30{:02X}'.format(red_component, blue_component)\n",
    "        purple_format = workbook.add_format({'bg_color': purple_hex, 'font_color': 'white'})\n",
    "        worksheet.write(row, col, round(x.item(), 2), purple_format)\n",
    "        col += 1\n",
    "    row += 1\n",
    "    col = 1\n",
    "workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8abd442-81d0-4786-9ef2-5e338d6ff015",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
