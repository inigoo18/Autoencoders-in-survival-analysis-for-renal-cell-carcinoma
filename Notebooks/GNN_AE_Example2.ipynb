{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e3b08a75-107b-4f43-b8ce-26cd03cbb495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: Data(x=[100, 1], edge_index=[2, 200])\n",
      "Loader: DataBatch(x=[100, 1], edge_index=[2, 200], batch=[100], ptr=[2])\n",
      "Batch DataBatch(x=[100, 1], edge_index=[2, 200], batch=[100], ptr=[2])\n",
      "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]) torch.Size([100, 100])\n",
      "Epoch [1/10], Average Loss: 2.9833\n",
      "Batch DataBatch(x=[100, 1], edge_index=[2, 200], batch=[100], ptr=[2])\n",
      "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]) torch.Size([100, 100])\n",
      "Epoch [2/10], Average Loss: 2.9146\n",
      "Batch DataBatch(x=[100, 1], edge_index=[2, 200], batch=[100], ptr=[2])\n",
      "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]) torch.Size([100, 100])\n",
      "Epoch [3/10], Average Loss: 2.8499\n",
      "Batch DataBatch(x=[100, 1], edge_index=[2, 200], batch=[100], ptr=[2])\n",
      "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]) torch.Size([100, 100])\n",
      "Epoch [4/10], Average Loss: 2.7892\n",
      "Batch DataBatch(x=[100, 1], edge_index=[2, 200], batch=[100], ptr=[2])\n",
      "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]) torch.Size([100, 100])\n",
      "Epoch [5/10], Average Loss: 2.7323\n",
      "Batch DataBatch(x=[100, 1], edge_index=[2, 200], batch=[100], ptr=[2])\n",
      "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]) torch.Size([100, 100])\n",
      "Epoch [6/10], Average Loss: 2.6791\n",
      "Batch DataBatch(x=[100, 1], edge_index=[2, 200], batch=[100], ptr=[2])\n",
      "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]) torch.Size([100, 100])\n",
      "Epoch [7/10], Average Loss: 2.6293\n",
      "Batch DataBatch(x=[100, 1], edge_index=[2, 200], batch=[100], ptr=[2])\n",
      "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]) torch.Size([100, 100])\n",
      "Epoch [8/10], Average Loss: 2.5824\n",
      "Batch DataBatch(x=[100, 1], edge_index=[2, 200], batch=[100], ptr=[2])\n",
      "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]) torch.Size([100, 100])\n",
      "Epoch [9/10], Average Loss: 2.5382\n",
      "Batch DataBatch(x=[100, 1], edge_index=[2, 200], batch=[100], ptr=[2])\n",
      "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]) torch.Size([100, 100])\n",
      "Epoch [10/10], Average Loss: 2.4966\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "# Step 1: Create Synthetic Graph Dataset\n",
    "num_nodes = 100\n",
    "num_features = 1\n",
    "\n",
    "# Generate random node features\n",
    "x = torch.randn(num_nodes, num_features)\n",
    "\n",
    "# Generate random adjacency matrix (assuming undirected graph)\n",
    "edge_index = torch.randint(0, num_nodes, (2, num_nodes * 2))\n",
    "edge_index = torch.unique(edge_index, dim=1)\n",
    "\n",
    "# Create synthetic graph data\n",
    "graph_data = Data(x=x, edge_index=edge_index)\n",
    "\n",
    "train_loader = DataLoader([graph_data], batch_size = 12)\n",
    "\n",
    "print(\"Data:\", graph_data)\n",
    "for i in train_loader:\n",
    "    print(\"Loader:\", i)\n",
    "\n",
    "# Step 2: Define Graph Autoencoder Model\n",
    "class GraphAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(GraphAutoencoder, self).__init__()\n",
    "        self.encoder = GCNConv(input_dim, hidden_dim)\n",
    "        self.decoder = GCNConv(hidden_dim, input_dim)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.encoder(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.decoder(x, edge_index)\n",
    "        return x\n",
    "\n",
    "\n",
    "def graph_autoencoder_loss(output, target_features, target_adjacency):\n",
    "    features_loss = nn.MSELoss()(output, target_features)\n",
    "\n",
    "    # Coalesce target_adjacency tensor\n",
    "    target_adjacency = target_adjacency.coalesce()\n",
    "\n",
    "\n",
    "    # Convert target_adjacency to dense tensor\n",
    "    target_adjacency_dense = torch.sparse_coo_tensor(target_adjacency.indices(), torch.ones_like(target_adjacency.values()), size=target_adjacency.size()).to_dense()\n",
    "\n",
    "    print(target_adjacency_dense, target_adjacency_dense.shape)\n",
    "\n",
    "    adjacency_pred = torch.matmul(output, output.t())\n",
    "\n",
    "    \n",
    "    # Calculate BCE loss\n",
    "    adjacency_loss = nn.BCEWithLogitsLoss()(adjacency_pred.flatten(), target_adjacency_dense.flatten().float())\n",
    "    \n",
    "    return features_loss + adjacency_loss\n",
    "\n",
    "\n",
    "\n",
    "# Step 4: Training Loop\n",
    "num_epochs = 10\n",
    "hidden_dim = 2\n",
    "model = GraphAutoencoder(num_features, hidden_dim)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Assuming train_loader is a PyTorch DataLoader containing the synthetic graph data\n",
    "num_batches = len(train_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0  # Reset total loss for the epoch\n",
    "    for batch in train_loader:\n",
    "        print(\"Batch\", batch)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch.x, batch.edge_index)\n",
    "        loss = graph_autoencoder_loss(output, batch.x, torch.sparse_coo_tensor(batch.edge_index, torch.ones_like(batch.edge_index[0]), size=(num_nodes, num_nodes)))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()  # Accumulate the loss for the epoch\n",
    "    avg_loss = total_loss / num_batches\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_loss:.4f}')\n",
    "\n",
    "\n",
    "# Step 5: Evaluation\n",
    "# You can use the trained model to reconstruct both the features and the adjacency matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ec623f4d-8126-467a-80eb-bf084ef3e9ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  1,  2,  2,  2,  3,  4,  5,  6,  6,  7,  7,  7,  7,  8,  8,  8,\n",
       "          8,  9,  9,  9, 10, 10, 11, 12, 12, 12, 14, 14, 15, 15, 16, 16, 17, 18,\n",
       "         18, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 21, 21, 21, 23, 23, 23, 24,\n",
       "         24, 27, 27, 28, 28, 28, 28, 28, 29, 30, 31, 32, 32, 32, 32, 33, 34, 35,\n",
       "         35, 35, 36, 36, 36, 39, 40, 40, 42, 42, 43, 43, 44, 44, 45, 45, 47, 47,\n",
       "         48, 48, 49, 49, 49, 49, 50, 52, 52, 53, 53, 54, 55, 55, 56, 56, 57, 57,\n",
       "         59, 59, 60, 60, 60, 61, 62, 62, 62, 63, 63, 63, 63, 63, 63, 64, 65, 65,\n",
       "         66, 66, 67, 67, 68, 68, 69, 69, 70, 70, 72, 72, 74, 74, 74, 75, 75, 75,\n",
       "         79, 79, 80, 81, 81, 83, 83, 83, 83, 84, 84, 85, 85, 86, 86, 86, 86, 87,\n",
       "         87, 87, 87, 87, 87, 88, 89, 89, 89, 89, 90, 90, 90, 91, 92, 92, 93, 93,\n",
       "         94, 95, 95, 95, 95, 96, 96, 96, 96, 96, 96, 97, 97, 97, 97, 98, 99],\n",
       "        [77, 68, 69, 23, 35, 53, 27, 41, 59,  4, 68, 16, 27, 82, 86,  5, 17, 43,\n",
       "         55, 56, 59, 61,  9, 77, 96, 29, 34, 91, 22, 62, 53, 78, 82, 93, 80, 15,\n",
       "         60, 28, 36, 61, 65, 67, 74, 98, 41, 62, 72,  2, 24, 46,  0,  5, 41, 37,\n",
       "         40, 22, 96,  3, 10, 15, 68, 98, 70,  1, 98, 16, 33, 68, 77, 85, 24, 38,\n",
       "         40, 61,  9, 36, 40, 95, 29, 86, 88, 99, 51, 95,  0, 19, 69, 73, 16, 19,\n",
       "         79, 98, 29, 50, 87, 96,  8, 10, 66, 14, 96, 51, 20, 42, 82, 97, 51, 75,\n",
       "          8, 22, 38, 47, 75, 78, 42, 57, 87,  8, 45, 59, 62, 69, 88, 59, 17, 52,\n",
       "         50, 67, 28, 89, 28, 43, 65, 68, 73, 91, 71, 99, 31, 58, 92, 46, 73, 88,\n",
       "         30, 50, 14, 17, 41,  4,  6, 44, 62, 19, 50, 32, 33, 10, 28, 49, 82, 26,\n",
       "         52, 73, 88, 93, 98, 85,  5, 18, 72, 92, 20, 36, 51, 80, 19, 84, 70, 91,\n",
       "         55,  5, 25, 75, 78,  9, 23, 29, 38, 52, 67, 33, 47, 52, 87, 79, 65]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "785b0d38-d66f-4bbc-96f5-3ee79188055b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[ 0,  1,  1,  2,  2,  2,  3,  4,  5,  6,  6,  7,  7,  7,\n",
       "                         7,  8,  8,  8,  8,  9,  9,  9, 10, 10, 11, 12, 12, 12,\n",
       "                        14, 14, 15, 15, 16, 16, 17, 18, 18, 19, 19, 19, 19, 19,\n",
       "                        19, 19, 20, 20, 20, 21, 21, 21, 23, 23, 23, 24, 24, 27,\n",
       "                        27, 28, 28, 28, 28, 28, 29, 30, 31, 32, 32, 32, 32, 33,\n",
       "                        34, 35, 35, 35, 36, 36, 36, 39, 40, 40, 42, 42, 43, 43,\n",
       "                        44, 44, 45, 45, 47, 47, 48, 48, 49, 49, 49, 49, 50, 52,\n",
       "                        52, 53, 53, 54, 55, 55, 56, 56, 57, 57, 59, 59, 60, 60,\n",
       "                        60, 61, 62, 62, 62, 63, 63, 63, 63, 63, 63, 64, 65, 65,\n",
       "                        66, 66, 67, 67, 68, 68, 69, 69, 70, 70, 72, 72, 74, 74,\n",
       "                        74, 75, 75, 75, 79, 79, 80, 81, 81, 83, 83, 83, 83, 84,\n",
       "                        84, 85, 85, 86, 86, 86, 86, 87, 87, 87, 87, 87, 87, 88,\n",
       "                        89, 89, 89, 89, 90, 90, 90, 91, 92, 92, 93, 93, 94, 95,\n",
       "                        95, 95, 95, 96, 96, 96, 96, 96, 96, 97, 97, 97, 97, 98,\n",
       "                        99],\n",
       "                       [77, 68, 69, 23, 35, 53, 27, 41, 59,  4, 68, 16, 27, 82,\n",
       "                        86,  5, 17, 43, 55, 56, 59, 61,  9, 77, 96, 29, 34, 91,\n",
       "                        22, 62, 53, 78, 82, 93, 80, 15, 60, 28, 36, 61, 65, 67,\n",
       "                        74, 98, 41, 62, 72,  2, 24, 46,  0,  5, 41, 37, 40, 22,\n",
       "                        96,  3, 10, 15, 68, 98, 70,  1, 98, 16, 33, 68, 77, 85,\n",
       "                        24, 38, 40, 61,  9, 36, 40, 95, 29, 86, 88, 99, 51, 95,\n",
       "                         0, 19, 69, 73, 16, 19, 79, 98, 29, 50, 87, 96,  8, 10,\n",
       "                        66, 14, 96, 51, 20, 42, 82, 97, 51, 75,  8, 22, 38, 47,\n",
       "                        75, 78, 42, 57, 87,  8, 45, 59, 62, 69, 88, 59, 17, 52,\n",
       "                        50, 67, 28, 89, 28, 43, 65, 68, 73, 91, 71, 99, 31, 58,\n",
       "                        92, 46, 73, 88, 30, 50, 14, 17, 41,  4,  6, 44, 62, 19,\n",
       "                        50, 32, 33, 10, 28, 49, 82, 26, 52, 73, 88, 93, 98, 85,\n",
       "                         5, 18, 72, 92, 20, 36, 51, 80, 19, 84, 70, 91, 55,  5,\n",
       "                        25, 75, 78,  9, 23, 29, 38, 52, 67, 33, 47, 52, 87, 79,\n",
       "                        65]]),\n",
       "       values=tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                      1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                      1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                      1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                      1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                      1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                      1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                      1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                      1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                      1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                      1, 1, 1, 1, 1, 1, 1]),\n",
       "       size=(100, 100), nnz=197, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sparse_coo_tensor(batch.edge_index, torch.ones_like(batch.edge_index[0]), size=(num_nodes, num_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "31f4059e-464b-4d9a-8865-b322a381b4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 2, 1, 0, 1],\n",
      "        [1, 1, 0, 0, 1]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 0.],\n",
       "        [1., 1., 1.],\n",
       "        [0., 1., 0.]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coo_indices = torch.randint(0, 3, (2, 5))  # Assuming 1000 nodes\n",
    "print(coo_indices)\n",
    "# Number of nodes in the graph\n",
    "num_nodes = 3\n",
    "\n",
    "# Create an empty adjacency matrix\n",
    "adj_matrix = torch.zeros(num_nodes, num_nodes)\n",
    "\n",
    "# Fill adjacency matrix using COO tensor\n",
    "adj_matrix[coo_indices[0], coo_indices[1]] = 1\n",
    "adj_matrix[coo_indices[1], coo_indices[0]] = 1\n",
    "adj_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "715cd5a1-22f0-4d54-a4ba-2788784607d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [2, 4, 6],\n",
       "        [3, 6, 9]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1,2,3])\n",
    "torch.ger(x, x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
